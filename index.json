[{"categories":null,"contents":"Intro ä»¥å‰ã¯ã€vagrant+virtualbox ã§ä»®æƒ³ãƒã‚·ãƒ³ã‚’ä½œæˆã—ã¦ã¾ã—ãŸãŒã€m2 mac ã«ç«¯æœ«ã‚’å¤‰ãˆãŸãŸã‚ã€multipass ã«åˆ‡ã‚Šæ›¿ãˆã¾ã—ãŸã€‚\nmultipass ã¯ã€Ubuntu ã®ä»®æƒ³ãƒã‚·ãƒ³ã‚’ç°¡å˜ã«ä½œæˆã§ãã‚‹ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚multipass ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€ä»®æƒ³ãƒã‚·ãƒ³ã®ä½œæˆã€èµ·å‹•ã€åœæ­¢ã€å‰Šé™¤ãªã©ã®æ“ä½œã‚’ç°¡å˜ã«è¡Œã†ã“ã¨ãŒã§ãã¾ã™ã€‚\ninstall $ brew install multipass ==\u0026gt; Installing Cask multipass ==\u0026gt; Running installer for multipass with sudo; the password may be necessary. Password: installer: Package name is multipass installer: Installing at base path / installer: The install was successful. ğŸº multipass was successfully installed! $ multipass version multipass 1.13.1+mac multipassd 1.13.1+mac åŸºæœ¬ã‚³ãƒãƒ³ãƒ‰ è©³ã—ãã¯ä»¥ä¸‹å‚ç…§ https://multipass.run/docs/multipass-cli-client # æ–°è¦ä½œæˆ $ multipass launch -n test-vm-01 Launched: test-vm-01 # ç¢ºèª $ multipass list Name State IPv4 Image test-vm-01 Running 192.168.64.2 Ubuntu 22.04 LTS $ multipass info test-vm-01 Name: test-vm-01 State: Running Snapshots: 0 IPv4: 192.168.64.2 Release: Ubuntu 22.04.4 LTS Image hash: 40ea1181447b (Ubuntu 22.04 LTS) CPU(s): 1 Load: 0.07 0.04 0.01 Disk usage: 1.6GiB out of 4.8GiB Memory usage: 150.2MiB out of 962.3MiB Mounts: -- # åœæ­¢ $ multipass stop test-vm-01 # èµ·å‹• $ multipass start test-vm-01 # å‰Šé™¤ (-p ã§æ°¸ç¶šåŒ–) $ multipass delete test-vm-01 -p # ã‚·ã‚§ãƒ«ã«å…¥ã‚‹ $ multipass shell test-vm-01 docker ç’°å¢ƒæ§‹ç¯‰ # éµä½œæˆ $ ssh-keygen -t rsa -b 4096 -C \u0026#34;\u0026#34; -f multipass # cloud-init ä½œæˆ $ vim multipass.yml #!/bin/sh AUTHORIZED_KEYS=$(cat multipass.pub ) cat \u0026gt; ./multipass_docker.yaml \u0026lt;\u0026lt; _EOF_ --- locale: en_US.UTF8 timezone: Asia/Tokyo package_upgrade: true users: - name: ubuntu sudo: ALL=(ALL) NOPASSWD:ALL ssh-authorized-keys: - ${AUTHORIZED_KEYS} packages: - docker - docker-compose - avahi-daemon - apt-transport-https - ca-certificates - curl - gnupg - lsb-release runcmd: - sudo curl -fsSL https://get.docker.com | sudo bash - sudo systemctl enable docker - sudo systemctl enable -s HUP ssh - sudo groupadd docker - sudo usermod -aG docker ubuntu _EOF_ # èµ·å‹• $ multipass launch -n test-vm-01 --cloud-init multipass.yml # ç¢ºèª $ multipass exec test-vm-01 docker version Client: Docker Engine - Community Version: 25.0.5 ... ","permalink":"https://h-neco.github.io/blog/vm-multipass/","tags":["Tools"],"title":"multipassã§ã®ä»®æƒ³ãƒã‚·ãƒ³ã®ä½œæˆ/Dockerç’°å¢ƒæ§‹ç¯‰"},{"categories":null,"contents":"Intro trivy ã¯ã€ã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ¡ãƒ¼ã‚¸ã®è„†å¼±æ€§è¨ºæ–­ã‚’è¡Œã†ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚trivy ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€ã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ¡ãƒ¼ã‚¸ã«å«ã¾ã‚Œã‚‹è„†å¼±æ€§ã‚’æ¤œå‡ºã—ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\ndocker ã®ç’°å¢ƒæ§‹ç¯‰ã«ã¤ã„ã¦ã¯ã“ã¡ã‚‰ ç’°å¢ƒæ§‹ç¯‰ ä½œæ¥­ã®å¤§æ  Dockerfile ã«å¯¾ã—ã¦ trivy ã§è¨ºæ–­ã‚’è¡Œã„ã¾ã™ã€‚ å•é¡Œãªã‘ã‚Œã°ã€ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ãƒ“ãƒ«ãƒ‰ã—ã€trivy ã§å†åº¦ã‚¹ã‚­ãƒ£ãƒ³ã‚’è¡Œã„ã¾ã™ã€‚ äº‹å‰æº–å‚™ é©å½“ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã—ã€Dockerfile ã‚’ä½œæˆã—ã¾ã™ã€‚ $ mkdir test $ vim test/Dockerfile FROM public.ecr.aws/nginx/nginx:1.25-alpine-slim EXPOSE 80/tcp è¨ºæ–­ DockerFile ã‚’ trivy ã§è¨ºæ–­ã—ã¾ã™ã€‚config ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚ $ docker run --rm -v /var/run/docker.sock:/var/run/docker.sock -v $(pwd)/test:/workdir aquasec/trivy config --ignorefile .trivy/.trivyignore --severity HIGH,CRITICAL . 2024-03-20T13:16:35.209Z\tINFO\tMisconfiguration scanning is enabled 2024-03-20T13:16:35.210Z\tINFO\tNeed to update the built-in policies 2024-03-20T13:16:35.211Z\tINFO\tDownloading the built-in policies... 46.13 KiB / 46.13 KiB [-------------------------------------------------------------------------------------------------------------------------------------------------] 100.00% ? p/s 100ms 2024-03-20T13:16:36.947Z\tINFO\tDetected config files: 1 Dockerfile (dockerfile) Tests: 20 (SUCCESSES: 19, FAILURES: 1, EXCEPTIONS: 0) Failures: 1 (HIGH: 1, CRITICAL: 0) HIGH: Specify at least 1 USER command in Dockerfile with non-root user as argument â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• Running containers with \u0026#39;root\u0026#39; user can lead to a container escape situation. It is a best practice to run containers as non-root users, which can be done by adding a \u0026#39;USER\u0026#39; statement to the Dockerfile. See https://avd.aquasec.com/misconfig/ds002 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ root ãƒ¦ãƒ¼ã‚¶ã§ã®å®Ÿè¡ŒãŒæ¤œå‡ºã•ã‚ŒãŸã®ã§ä¿®æ­£ã—ã¦ã¿ã¾ã™ã€‚ $ vim test/Dockerfile FROM public.ecr.aws/nginx/nginx:1.25-alpine-slim RUN apk add --no-cache shadow \u0026amp;\u0026amp; \\ useradd -u 9000 test USER test # å†ç¢ºèª docker run --rm -v /var/run/docker.sock:/var/run/docker.sock -v $(pwd)/test:/workdir aquasec/trivy config --ignorefile .trivy/.trivyignore --severity HIGH,CRITICAL . 2024-03-20T13:28:55.680Z\tINFO\tMisconfiguration scanning is enabled 2024-03-20T13:28:55.681Z\tINFO\tNeed to update the built-in policies 2024-03-20T13:28:55.682Z\tINFO\tDownloading the built-in policies... 46.13 KiB / 46.13 KiB [-------------------------------------------------------------------------------------------------------------------------------------------------] 100.00% ? p/s 100ms 2024-03-20T13:28:57.980Z\tINFO\tDetected config files: 1 æ¤œå‡ºã—ãªããªã£ãŸã®ã§ build ã—ã¾ã™ã€‚ $ cd test \u0026amp;\u0026amp; docker build -f Dockerfile -t test-nginx-01:latest . ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ trivy ã§ã‚¹ã‚­ãƒ£ãƒ³ã—ã¾ã™ã€‚image ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚ ubuntu@test-vm-01:~$ docker run --rm -v /var/run/docker.sock:/var/run/docker.sock -v $(pwd)/test:/workdir aquasec/trivy image test-nginx-01:latest 2024-03-20T13:39:44.909Z\tINFO\tNeed to update DB 2024-03-20T13:39:44.909Z\tINFO\tDB Repository: ghcr.io/aquasecurity/trivy-db:2 2024-03-20T13:39:44.909Z\tINFO\tDownloading DB... 1.21 MiB / 44.46 MiB [-\u0026gt;_____________________________________________________________] 2.71% ? p/s ?2.38 MiB / 44.46 MiB [---\u0026gt;___________________________________________________________] 5.36% ? p/s ?3.81 MiB / 44.46 MiB [-----\u0026gt;_________________________________________________________] 8.58% ? p/s ?4.92 MiB / 44.46 MiB [-----\u0026gt;____________________________________________] 11.06% 6.17 MiB p/s ETA 6s6.23 MiB / 44.46 MiB [-------\u0026gt;__________________________________________] 14.00% 6.17 MiB p/s ETA 6s7.35 MiB / 44.46 MiB [--------\u0026gt;_________________________________________] 16.54% 6.17 MiB p/s ETA 6s9.36 MiB / 44.46 MiB [----------\u0026gt;_______________________________________] 21.05% 6.25 MiB p/s ETA 5s11.68 MiB / 44.46 MiB [------------\u0026gt;____________________________________] 26.28% 6.25 MiB p/s ETA 5s14.02 MiB / 44.46 MiB [---------------\u0026gt;_________________________________] 31.52% 6.25 MiB p/s ETA 4s16.96 MiB / 44.46 MiB [------------------\u0026gt;______________________________] 38.14% 6.67 MiB p/s ETA 4s20.00 MiB / 44.46 MiB [----------------------\u0026gt;__________________________] 44.98% 6.67 MiB p/s ETA 3s22.54 MiB / 44.46 MiB [------------------------\u0026gt;________________________] 50.69% 6.67 MiB p/s ETA 3s25.50 MiB / 44.46 MiB [----------------------------\u0026gt;____________________] 57.36% 7.16 MiB p/s ETA 2s28.53 MiB / 44.46 MiB [-------------------------------\u0026gt;_________________] 64.18% 7.16 MiB p/s ETA 2s30.86 MiB / 44.46 MiB [----------------------------------\u0026gt;______________] 69.41% 7.16 MiB p/s ETA 1s33.75 MiB / 44.46 MiB [-------------------------------------\u0026gt;___________] 75.91% 7.58 MiB p/s ETA 1s36.58 MiB / 44.46 MiB [----------------------------------------\u0026gt;________] 82.27% 7.58 MiB p/s ETA 1s39.46 MiB / 44.46 MiB [-------------------------------------------\u0026gt;_____] 88.77% 7.58 MiB p/s ETA 0s42.50 MiB / 44.46 MiB [----------------------------------------------\u0026gt;__] 95.60% 8.03 MiB p/s ETA 0s44.46 MiB / 44.46 MiB [-----------------------------------------------\u0026gt;] 100.00% 8.03 MiB p/s ETA 0s44.46 MiB / 44.46 MiB [-----------------------------------------------\u0026gt;] 100.00% 8.03 MiB p/s ETA 0s44.46 MiB / 44.46 MiB [-----------------------------------------------\u0026gt;] 100.00% 7.72 MiB p/s ETA 0s44.46 MiB / 44.46 MiB [-----------------------------------------------\u0026gt;] 100.00% 7.72 MiB p/s ETA 0s44.46 MiB / 44.46 MiB [-----------------------------------------------\u0026gt;] 100.00% 7.72 MiB p/s ETA 0s44.46 MiB / 44.46 MiB [-----------------------------------------------\u0026gt;] 100.00% 7.22 MiB p/s ETA 0s44.46 MiB / 44.46 MiB [--------------------------------------------------] 100.00% 9.01 MiB p/s 5.1s2024-03-20T13:39:51.416Z\tINFO\tVulnerability scanning is enabled 2024-03-20T13:39:51.416Z\tINFO\tSecret scanning is enabled 2024-03-20T13:39:51.416Z\tINFO\tIf your scanning is slow, please try \u0026#39;--scanners vuln\u0026#39; to disable secret scanning 2024-03-20T13:39:51.416Z\tINFO\tPlease see also https://aquasecurity.github.io/trivy/v0.50/docs/scanner/secret/#recommendation for faster secret detection 2024-03-20T13:39:51.923Z\tINFO\tDetected OS: alpine 2024-03-20T13:39:51.924Z\tINFO\tDetecting Alpine vulnerabilities... 2024-03-20T13:39:51.925Z\tINFO\tNumber of language-specific files: 0 test-nginx-01:latest (alpine 3.18.6) ==================================== Total: 0 (UNKNOWN: 0, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 0) ã¾ã¨ã‚ ã‚¤ãƒ¡ãƒ¼ã‚¸ã®ã‚¹ã‚­ãƒ£ãƒ³ã¨ Dockerfile ã®è¨ºæ–­ã‚’è¡Œã„ã¾ã—ãŸã€‚ ç°¡å˜ã«ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨ºæ–­ã‚’è¡Œã†ã“ã¨ãŒã§ãã‚‹ã®ã§ã€ç©æ¥µçš„ã«åˆ©ç”¨ã—ã¦ã„ããŸã„ã§ã™ã€‚ ãŠã¾ã‘ docker-compose ã§å®Ÿè¡Œã™ã‚‹å ´åˆã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚ ubuntu@test-vm-01:~$ cat docker-compose.yml version: \u0026#34;3\u0026#34; services: trivy-scan: image: bitnami/trivy:latest platform: linux/arm64 volumes: - ./test:/workdir working_dir: \u0026#34;/workdir\u0026#34; entrypoint: sh -c \u0026#39;trivy config --ignorefile .trivy/.trivyignore --severity HIGH,CRITICAL .\u0026#39; ","permalink":"https://h-neco.github.io/blog/docker-trivy/","tags":["Security"],"title":"Trivy ã‚’ç”¨ã„ãŸã‚³ãƒ³ãƒ†ãƒŠImage,DockerFileã¸ã®è„†å¼±æ€§è¨ºæ–­"},{"categories":null,"contents":"ChatGPT+Mermaid ã§ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å›³ã‚’ä½œæˆã™ã‚‹ ChatGPT ã¨ Mermaid ã‚’ä½¿ã£ã¦ã€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å›³ã‚’ä½œæˆã—ã¦ã¿ã¾ã—ãŸã€‚\nChatGPT ã¨ Mermaid ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å›³ã‚’ç°¡å˜ã«ä½œæˆã§ãã¾ã™ã€‚ChatGPT ã¯è‡ªç„¶ãªæ–‡ç« ç”Ÿæˆã«å„ªã‚Œã¦ãŠã‚Šã€Mermaid ã¯ã‚·ãƒ³ãƒ—ãƒ«ãªè¨˜æ³•ã§ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å›³ã‚’æç”»ã§ãã¾ã™ã€‚ã“ã®çµ„ã¿åˆã‚ã›ã«ã‚ˆã‚Šã€æ‰‹è»½ã«è¦ç´„ã‚„èª¬æ˜ã‚’è¡Œã„ãªãŒã‚‰ã€è¦–è¦šçš„ãªå›³ã‚’ç”Ÿæˆã§ãã¾ã™ã€‚AI ãŒç”Ÿæˆã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’å…ƒã«ã€Mermaid ã‚’ä½¿ã£ã¦ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å›³ã‚’ä½œæˆã™ã‚‹ã“ã¨ã§ã€è¤‡é›‘ãªãƒ—ãƒ­ã‚»ã‚¹ã‚„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’è¦–è¦šçš„ã«ç†è§£ã—ã‚„ã™ããªã‚Šã¾ã™ã€‚\nç°¡å˜ãªãƒãƒƒãƒã®å›³ã‚’ä½œæˆã—ã¦ã¿ã¾ã—ãŸ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ã®æŒ‡ç¤º ã€Œ\u0026ldquo;a\u0026quot;ãŒ\u0026quot;b\u0026quot;ã«å¯¾ã—ã¦\u0026quot;x\u0026quot;ã‚’éåŒæœŸã§è¦æ±‚ã—ã€ãã®å¾Œ\u0026quot;b\u0026quot;ã®çŠ¶æ…‹ã‚’ç¢ºèªã—ç¶šã‘ã‚‹ã¨ã„ã†ãƒ—ãƒ­ã‚»ã‚¹ã‚’ Mermaid ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å›³ã§ä½œæˆã—ã¦ãã ã•ã„ã€‚çŠ¶æ…‹ãŒå¤‰æ›´ã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã€\u0026ldquo;a\u0026quot;ãŒçŠ¶æ…‹ç¢ºèªã‚’ç¶™ç¶šã—ã€çŠ¶æ…‹ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã¯ã€\u0026ldquo;b\u0026quot;ãŒ\u0026quot;a\u0026quot;ã«ãã®æ—¨ã‚’é€šçŸ¥ã™ã‚‹ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚‚å›³ã«å«ã‚ã¦ãã ã•ã„ã€‚ã€\nå›ç­” ã‚ãªãŸãŒæ±‚ã‚ã¦ã„ã‚‹ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å›³ã¯ã€ä»¥ä¸‹ã®ã‚ˆã†ãªå½¢ã«ãªã‚Šã¾ã™ã€‚\nmermaid sequenceDiagram participant a participant b a-\u0026gt;\u0026gt;b: xã‚’éåŒæœŸã§è¦æ±‚ loop çŠ¶æ…‹ç¢ºèª a-\u0026gt;\u0026gt;b: bã®çŠ¶æ…‹ã‚’ç¢ºèª opt å¤‰æ›´ãªã— a-\u0026gt;\u0026gt;a: çŠ¶æ…‹ã®ç¢ºèªã‚’ç¶™ç¶š end b--\u0026gt;\u0026gt;a: çŠ¶æ…‹å¤‰æ›´ã‚ã‚Š end ã“ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å›³ã¯ã€\u0026ldquo;a\u0026quot;ãŒ\u0026quot;b\u0026quot;ã«éåŒæœŸã§\u0026quot;x\u0026quot;ã‚’è¦æ±‚ã—ã€ãã®å¾Œ\u0026quot;b\u0026quot;ã®çŠ¶æ…‹ã‚’ç¢ºèªã—ç¶šã‘ã‚‹ãƒ—ãƒ­ã‚»ã‚¹ã‚’è¡¨ç¾ã—ã¦ã„ã¾ã™ã€‚\u0026ldquo;b\u0026quot;ã®çŠ¶æ…‹ãŒå¤‰æ›´ã•ã‚Œãªã„å ´åˆã€\u0026ldquo;a\u0026quot;ã¯çŠ¶æ…‹ã®ç¢ºèªã‚’ç¶šã‘ã¾ã™ã€‚ä¸€æ–¹ã€\u0026ldquo;b\u0026quot;ã®çŠ¶æ…‹ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã€\u0026ldquo;b\u0026quot;ã¯\u0026quot;a\u0026quot;ã«ãã®æ—¨ã‚’é€šçŸ¥ã—ã¾ã™ã€‚\n","permalink":"https://h-neco.github.io/blog/chatgpt-mermaid/","tags":["Tools"],"title":"ChatGPT+Mermaidã§ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å›³ã‚’ä½œæˆã™ã‚‹"},{"categories":null,"contents":"CloudFrontFunction / LambdaEdge ã«ã¤ã„ã¦ CloudFront Functions ã¯ã€Amazon CloudFront ã®ã‚µãƒ¼ãƒ“ã‚¹ã§ã‚ã‚Šã€Lambda@Edge ã‚ˆã‚Šæ‰‹å‰ã§å‹•ä½œã—ã€ã‚·ãƒ³ãƒ—ãƒ«ãªå‡¦ç†ã‚’é«˜é€Ÿã‹ã¤å®‰ä¾¡ã«å®Ÿè¡Œã§ãã‚‹ã‚ˆã†ã«è¨­è¨ˆã•ã‚ŒãŸæ©Ÿèƒ½ã§ã™ã€‚å¾“æ¥ã® Lambda@Edge ã¯ã€CloudFront ã®ã‚¨ãƒƒã‚¸ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§å‹•ä½œã™ã‚‹ã‚«ã‚¹ã‚¿ãƒ ã® AWS Lambda é–¢æ•°ã‚’ä½œæˆã—ã¦ã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¾ãŸã¯ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å‡¦ç†ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ä¸€æ–¹ã€CloudFront Functions ã¯ã‚ˆã‚Šã‚·ãƒ³ãƒ—ãƒ«ã§è»½é‡ã§ã‚ã‚Šã€Lambda@Edge ã‚ˆã‚Šã‚‚ä½ã„ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã¨é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æŒã£ã¦ã„ã¾ã™ã€‚\nCloudFront Functions ã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€ã‚ˆã‚Šãƒ¦ãƒ¼ã‚¶ãƒ¼ã«è¿‘ã„ã‚¨ãƒƒã‚¸ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†ã§ãã‚‹ãŸã‚ã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ãŒçŸ­ç¸®ã•ã‚Œã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¨ã‚¯ã‚¹ãƒšãƒªã‚¨ãƒ³ã‚¹ãŒå‘ä¸Šã—ã¾ã™ã€‚ã¾ãŸã€ã‚³ã‚¹ãƒˆé¢ã§ã‚‚ Lambda@Edge ã‚ˆã‚Šã‚‚çµŒæ¸ˆçš„ã§ã‚ã‚‹ãŸã‚ã€ã‚·ãƒ³ãƒ—ãƒ«ãªå‡¦ç†ã«ã¯ CloudFront Functions ãŒé©ã—ã¦ã„ã¾ã™ã€‚\nã•ã‚‰ã«ã€CloudFront Functions ã¨ Lambda@Edge ã‚’çµ„ã¿åˆã‚ã›ã¦ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚‚å¯èƒ½ã§ã™ã€‚ä¾‹ãˆã°ã€ã‚·ãƒ³ãƒ—ãƒ«ãªå‡¦ç†ã‚„ãƒ˜ãƒƒãƒ€ãƒ¼ã®æ“ä½œã€URL ã®æ›¸ãæ›ãˆãªã©ã®ã‚¿ã‚¹ã‚¯ã‚’ CloudFront Functions ã§å‡¦ç†ã—ã€ã‚ˆã‚Šé«˜åº¦ãªå‡¦ç†ã‚’å¿…è¦ã¨ã™ã‚‹å ´åˆã«ã¯ Lambda@Edge ã§è¿½åŠ ã®å‡¦ç†ã‚’è¡Œã†ã“ã¨ãŒã§ãã¾ã™ã€‚ ã“ã‚Œã«ã‚ˆã‚Šã€ã‚ˆã‚ŠåŠ¹ç‡çš„ã§é«˜é€Ÿãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ‡ãƒªãƒãƒªãƒ¼ã‚µãƒ¼ãƒ“ã‚¹ã‚’æä¾›ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ãŸã‚ã€AWS ã®ã‚¯ãƒ©ã‚¦ãƒ‰ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ã‚’æ´»ç”¨ã—ãŸã‚¦ã‚§ãƒ–ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®é…ä¿¡ã‚’è¡Œã†éš›ã«ä¾¿åˆ©ã§ã™ã€‚\næ¯”è¼ƒè¡¨ ç‰¹å¾´ CloudFrontFunction Lambda@Edge ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã‚µãƒãƒ¼ãƒˆ JavaScript (ECMAScript 5.1 æº–æ‹ ) Node.jsã€Python å®Ÿè¡Œå ´æ‰€ 218 ä»¥ä¸Šã® CloudFront ã‚¨ãƒƒã‚¸ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ 13 ã® CloudFront ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã®ã‚¨ãƒƒã‚¸ã‚­ãƒ£ãƒƒã‚·ãƒ¥ ã‚µãƒãƒ¼ãƒˆã•ã‚Œã‚‹ CloudFront ãƒˆãƒªã‚¬ãƒ¼ ãƒ“ãƒ¥ãƒ¼ã‚¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆã€ãƒ“ãƒ¥ãƒ¼ã‚¢ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã€ã‚ªãƒªã‚¸ãƒ³ãƒªã‚¯ã‚¨ã‚¹ãƒˆã€ã‚ªãƒªã‚¸ãƒ³ãƒ¬ã‚¹ãƒãƒ³ã‚¹ ãƒ“ãƒ¥ãƒ¼ã‚¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆã€ãƒ“ãƒ¥ãƒ¼ã‚¢ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã€ã‚ªãƒªã‚¸ãƒ³ãƒªã‚¯ã‚¨ã‚¹ãƒˆã€ã‚ªãƒªã‚¸ãƒ³ãƒ¬ã‚¹ãƒãƒ³ã‚¹ æœ€å¤§å®Ÿè¡Œæ™‚é–“ 1 ãƒŸãƒªç§’æœªæº€ 5 ç§’ (ãƒ“ãƒ¥ãƒ¼ã‚¢ãƒˆãƒªã‚¬ãƒ¼)ã€30 ç§’ (ã‚ªãƒªã‚¸ãƒ³ãƒˆãƒªã‚¬ãƒ¼) æœ€å¤§ãƒ¡ãƒ¢ãƒª 2 MB 128 MB (ãƒ“ãƒ¥ãƒ¼ã‚¢ãƒˆãƒªã‚¬ãƒ¼)ã€10 GB (ã‚ªãƒªã‚¸ãƒ³ãƒˆãƒªã‚¬ãƒ¼) åˆè¨ˆãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚µã‚¤ã‚º 10 KB 1 MB (ãƒ“ãƒ¥ãƒ¼ã‚¢ãƒˆãƒªã‚¬ãƒ¼)ã€50 MB (ã‚ªãƒªã‚¸ãƒ³ãƒˆãƒªã‚¬ãƒ¼) ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ ãªã— ã‚ã‚Š ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã‚¢ã‚¯ã‚»ã‚¹ ãªã— ã‚ã‚Š ãƒªã‚¯ã‚¨ã‚¹ãƒˆæœ¬æ–‡ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ ãªã— ã‚ã‚Š æ–™é‡‘ ç„¡æ–™åˆ©ç”¨æ ã‚ã‚Šã€‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆã”ã¨ã«èª²é‡‘ã€‚ ç„¡æ–™åˆ©ç”¨æ ãªã—ã€‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¨é–¢æ•°ã®å®Ÿè¡Œæ™‚é–“ã”ã¨ã«èª²é‡‘ã€‚ ã¾ã¨ã‚ãƒ»è€ƒå¯Ÿ ã©ã¡ã‚‰ã«ã™ã‚‹ã‹ã¯å‡¦ç†æ™‚é–“ã‹éµã«ãªã‚Šãã†ã§ã™ã€‚\nCloudFrontFunctions ã¯åŒæ™‚å®Ÿè¡Œæ•°ã®ã‚¯ã‚©ãƒ¼ã‚¿ã¨ã‹ãŒå…¬é–‹ã•ã‚Œã¦ãŠã‚‰ãšã€ãŠãã‚‰ãç„¡ã„ã®ã§ã¯ãªã„ã‹ã¨æ€ã£ã¦ã¾ã™ã€‚\nCloudFrontFunctions ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ å®Ÿéš›ã«ä½¿ã£ã¦ã¿ãŸã®ã§ CloudFrontFunctions ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã‚’è¼‰ã£ã‘ã¦ã¿ã¾ã™ã€‚\nLambdaEdge ã¯ãƒ­ãƒ¼ãƒ«ä½œã£ãŸã‚Šãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹ã®ãŒé¢å€’ãªã®ã§ã™ãŒã€CloudFrontFunctions ã¯ã‚³ãƒ¼ãƒ‰ã ã‘æ›¸ã‘ã°ã„ã„ã®ã§æ¥½ã§ã™ã­ã€‚\nIP åˆ¶é™ã‚’ã‹ã‘ã‚‹ function handler(event) { var request = event.request; var viewer = event.viewer; var allowIP = [\u0026#34;1.1.1.1\u0026#34;, \u0026#34;0.0.0.0\u0026#34;]; if (allowIP.indexOf(viewer.ip) !== -1) { return request; } return { statusCode: 403, statusDescription: \u0026#34;Forbidden\u0026#34;, body: \u0026#34;Access to this resource is forbidden.\u0026#34;, }; } www ãªã—ã‹ã‚‰ www ã‚ã‚Šã«ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆã•ã›ã‚‹ var querystring = require(\u0026#34;querystring\u0026#34;); // ã‚¯ã‚¨ãƒªã‚¹ãƒˆãƒªãƒ³ã‚°ã‚’æ–‡å­—åˆ—åŒ–ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° function stringifyQueryString(eventQueryString) { var query = {}; Object.entries(eventQueryString).forEach(function (q) { query[q[0]] = q[1].multiValue ? q[1].multiValue.map(function (m) { return m.value; }) : q[1].value; }); return querystring.stringify(query); } function handler(event) { var request = event.request; var newurl = \u0026#34;https://www.domain.jp\u0026#34; + request.uri; // ã‚¯ã‚¨ãƒªã‚¹ãƒˆãƒªãƒ³ã‚°ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯ã€æ–‡å­—åˆ—åŒ–ã—ã¦ newurl ã«è¿½åŠ  if (Object.keys(request.querystring).length \u0026gt; 0) newurl += \u0026#34;?\u0026#34; + stringifyQueryString(request.querystring); return { statusCode: 301, statusDescription: \u0026#34;Found\u0026#34;, headers: { location: { value: newurl } }, }; } Basic èªè¨¼ã‚’ã‹ã‘ã‚‹ï¼ˆpath ã«ã‚ˆã£ã¦èªè¨¼ã‚’å¤‰ãˆã‚‹ï¼‰ å‡¦ç†æ™‚é–“ã‚’æ°—ã«ã—ã¦ã€äºˆã‚ ID,PW ã‚’ base64 ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦ã¾ã™ã€‚ function handler(event) { var request = event.request; var headers = request.headers; var viewer = event.viewer; var idpw = \u0026#34;dGVzdF8xOnRlc3RfMg==\u0026#34;; // common IDPW var allowPathFlag = false; var optionPathSettingFlag = false; var pathRules = { \u0026#34;^/test/*\u0026#34;: { idpw: \u0026#34;dGVzdF8xOnRlc3RfMw==\u0026#34; }, \u0026#34;^/aiu/*\u0026#34;: { idpw: \u0026#34;dGVzdF8xOnRlc3RfMw==\u0026#34; }, \u0026#34;^/hoge/aiu/*\u0026#34;: { idpw: null }, }; for (var path in pathRules) { if (pathRules.hasOwnProperty(path) \u0026amp;\u0026amp; new RegExp(path).test(request.uri)) { allowPathFlag = true; if (pathRules[path].idpw !== null) { optionPathSettingFlag = true; idpw = pathRules[path].idpw; break; } } } if (allowPathFlag \u0026amp;\u0026amp; !optionPathSettingFlag) { return { request: request }; } // IDPW var authString = \u0026#34;Basic \u0026#34; + idpw; if (typeof headers.authorization === \u0026#34;undefined\u0026#34; || headers.authorization.value !== authString) { return { statusCode: 401, statusDescription: \u0026#34;Unauthorized\u0026#34;, headers: { \u0026#34;www-authenticate\u0026#34;: { value: \u0026#34;Basic\u0026#34; } }, request: request, }; } return { request: request }; } terraform ã§ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹ã¨ã è¶…ã‚«ãƒ³ã‚¿ãƒ³ã€‚ã“ã‚“ãªæ„Ÿã˜ã§ãƒ‡ãƒ—ãƒ­ã‚¤ã§ãã¾ã™ã€‚\nresource \u0026#34;aws_cloudfront_function\u0026#34; \u0026#34;hoge\u0026#34; { name = \u0026#34;hoge-${terraform.workspace}\u0026#34; runtime = \u0026#34;cloudfront-js-1.0\u0026#34; publish = true code = file(\u0026#34;hogehoge.js\u0026#34;) } ","permalink":"https://h-neco.github.io/blog/aws-cloudfront-functions/","tags":["AWS"],"title":"CloudFrontFunctionã¨LambdaEdgeã®é•ã„"},{"categories":null,"contents":"ã¯ã˜ã‚ã« docker ã§ terraform ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã® docker-compose.yml ã‚’ä½œæˆã—ã¾ã—ãŸã€‚\nãƒ¡ãƒªãƒƒãƒˆ ç’°å¢ƒã®çµ±ä¸€ Docker ã¯ç’°å¢ƒã®çµ±ä¸€ã‚’å®¹æ˜“ã«ã—ã¾ã™ã€‚ç•°ãªã‚‹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã‚„ OS ã§ä½œæ¥­ã—ã¦ã„ã‚‹å ´åˆã§ã‚‚ã€Docker ã‚³ãƒ³ãƒ†ãƒŠå†…ã§ Terraform ã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ã§ã€å®Ÿè¡Œç’°å¢ƒã‚’ä¸€è²«ã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç† Terraform ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã¯é‡è¦ã§ã™ã€‚ç•°ãªã‚‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚„ç’°å¢ƒã§è¤‡æ•°ã® Terraform ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã€Docker ã‚³ãƒ³ãƒ†ãƒŠå†…ã§ Terraform ã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ã§ã€å„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚„ç’°å¢ƒã”ã¨ã«é©åˆ‡ãª Terraform ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç®¡ç†ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ windows ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ tfenv ãŒä½¿ãˆãªã„ã®ã§ã€docker ã§ç®¡ç†ã™ã‚‹ã®ãŒè‰¯ã„ã‹ã¨æ€ã„ã¾ã™ã€‚ ã‚„ã‚‹ã“ã¨ ç’°å¢ƒå¤‰æ•°ã®ã‚»ãƒƒãƒˆ export AWS_DEFAULT_REGION=ap-northeast-1 export AWS_ACCESS_KEY_ID=xxxxxx export AWS_SECRET_ACCESS_KEY=xxxxxx docker-compose.yml ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ version: \u0026#34;3\u0026#34; services: terraform: image: hashicorp/terraform:1.5.2 platform: linux/x86_64 volumes: - ~/.aws:/root/.aws - ./:/workdir working_dir: \u0026#34;/workdir\u0026#34; environment: - AWS_ACCESS_KEY_ID - AWS_SECRET_ACCESS_KEY - AWS_DEFAULT_REGION entrypoint: sh -c \u0026#39;terraform init \u0026amp;\u0026amp; terraform workspace select \u0026#34;${WORKSPACE}\u0026#34; 2\u0026gt;/dev/null || terraform workspace new \u0026#34;${WORKSPACE}\u0026#34; \u0026amp;\u0026amp; terraform \u0026#34;${COMMAND}\u0026#34;\u0026#39; terraform ã®å®Ÿè¡Œ # ã‚³ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿ãƒ¼ã®å®Ÿè¡Œ export WORKSPACE=\u0026#34;prod\u0026#34; COMMAND=\u0026#34;fmt\u0026#34; \u0026amp;\u0026amp; docker-compose -p ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå run --rm terraform # ã‚³ãƒ¼ãƒ‰æ§‹æ–‡ãƒã‚§ãƒƒã‚¯ã®å®Ÿè¡Œ export WORKSPACE=\u0026#34;prod\u0026#34; COMMAND=\u0026#34;validate\u0026#34; \u0026amp;\u0026amp; docker-compose -p ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå run --rm terraform # å®Ÿè¡Œè¨ˆç”»ã®ç¢ºèª export WORKSPACE=\u0026#34;prod\u0026#34; COMMAND=\u0026#34;plan\u0026#34; \u0026amp;\u0026amp; docker-compose -p ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå run --rm terraform ","permalink":"https://h-neco.github.io/blog/docker-terraform/","tags":["DevOps"],"title":"dockerã§terraformã‚’å®Ÿè¡Œã™ã‚‹"},{"categories":null,"contents":"ã¯ã˜ã‚ã« BitBucketPipelines ã§ image ã® push ã‚’è¡Œã£ã¦ã„ã¾ã—ãŸãŒã€cpu ãŒãƒãƒ«ãƒãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã«å¯¾å¿œã—ã¦ãŠã‚‰ãšã€x86_64 ã®ã¿ã—ã‹å¯¾å¿œã—ã¦ã„ãªã„ãŸã‚ã€ã‚¤ãƒ¡ãƒ¼ã‚¸ã® push ã‚’ CodeBuild ã§è¡Œã†ã“ã¨ã«ã—ã¾ã—ãŸã€‚ arm64 ã§ ECS ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ã¨ã‚³ã‚¹ãƒˆãŒ 20ï¼…è½ã¡ã€ä½¿ã„æ–¹ã«ã‚ˆã£ã¦ã¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå‘ä¸Šã™ã‚‹ã‚‰ã—ã„ã€‚\nä»Šã¾ã§ [BitBucketPipelines]ã€€â†’ [awsECR] å¤‰æ›´å¾Œ [BitBucketPipelines]ã€€â†’ [awsCodeBuild]ã€€â†’ [awsECR] çµæœ ã‚³ã‚¹ãƒˆãŒ 20%ãã‚‰ã„è½ã¡ãŸã€‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯ã¾ã ã‚µãƒ¼ãƒ“ã‚¹ã‚¤ãƒ³ã—ã¦ãªã„ãŸã‚åˆ†ã‹ã‚‰ãªã„\nã‚„ã‚‹ã“ã¨ CodeBuild ã®è¨­å®š æ§‹æˆ /image/ä»¥ä¸‹ã® Dockerfile ã‚’ build ã—ã¦ ECR ã« push ã™ã‚‹ /image/ä»¥ä¸‹ã« buildspec.yml ã‚’é…ç½® Bitbucket ã‹ã‚‰ CodeBuild ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã® script ç”¨æ„ bitbuket-pipelines.yml ã®ä¿®æ­£ CodeBuild ã®è¨­å®š data \u0026#34;aws_region\u0026#34; \u0026#34;this\u0026#34; {} resource \u0026#34;aws_codebuild_project\u0026#34; \u0026#34;ecr\u0026#34; { badge_enabled = false build_timeout = 20 // 20åˆ† concurrent_build_limit = 1 // ä¸¦åˆ—å®Ÿè¡Œæ•° encryption_key = \u0026#34;arn:aws:kms:${data.aws_region.this.name}:${data.aws_caller_identity.self.account_id}:alias/aws/s3\u0026#34; name = \u0026#34;ecr-build-${terraform.workspace}\u0026#34; project_visibility = \u0026#34;PRIVATE\u0026#34; queued_timeout = 480 service_role = aws_iam_role.codebuild_role.arn tags = { Environment = \u0026#34;${terraform.workspace}\u0026#34; Name = \u0026#34;ecr-build-${terraform.workspace}\u0026#34; } environment { compute_type = \u0026#34;BUILD_GENERAL1_SMALL\u0026#34; // 1vCPU, 3.75GB image = \u0026#34;aws/codebuild/amazonlinux2-aarch64-standard:3.0\u0026#34; type = \u0026#34;ARM_CONTAINER\u0026#34; image_pull_credentials_type = \u0026#34;CODEBUILD\u0026#34; privileged_mode = true // dockerã‚³ãƒãƒ³ãƒ‰ã‚’å©ãå ´åˆã¯å¿…é ˆ } artifacts { type = \u0026#34;NO_ARTIFACTS\u0026#34; } source { location = \u0026#34;bucketname/buildspec/\u0026#34; buildspec = \u0026#34;codebuild/${terraform.workspace}/buildspec.yml\u0026#34; report_build_status = false type = \u0026#34;S3\u0026#34; } } #------------------------------------------------------------# # code build role #------------------------------------------------------------# data \u0026#34;aws_iam_policy_document\u0026#34; \u0026#34;codebuild_role\u0026#34; { statement { sid = \u0026#34;1\u0026#34; effect = \u0026#34;Allow\u0026#34; actions = [\u0026#34;sts:AssumeRole\u0026#34;] principals { type = \u0026#34;Service\u0026#34; identifiers = [ \u0026#34;codebuild.amazonaws.com\u0026#34; ] } } } resource \u0026#34;aws_iam_role\u0026#34; \u0026#34;codebuild_role\u0026#34; { name = \u0026#34;codebuild-ecr-build-${terraform.workspace}\u0026#34; assume_role_policy = data.aws_iam_policy_document.codebuild_role.json } #------------------------------------------------------------# # code build atached policy s3 access #------------------------------------------------------------# resource \u0026#34;aws_iam_policy\u0026#34; \u0026#34;codebuild_s3_access_policy\u0026#34; { name = \u0026#34;codebuild-s3-access-policy-${terraform.workspace}\u0026#34; description = \u0026#34;codebuild_s3_access_policy\u0026#34; policy = \u0026lt;\u0026lt;EOT { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:GetObjectVersion\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::bucketname/buildspec/\u0026#34;, \u0026#34;arn:aws:s3:::bucketname/buildspec/*\u0026#34; ] }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::bucketname\u0026#34; ], \u0026#34;Action\u0026#34;: [ \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;s3:GetBucketLocation\u0026#34; ] } ] } EOT } resource \u0026#34;aws_iam_role_policy_attachment\u0026#34; \u0026#34;codebuild_s3_access_policy\u0026#34; { role = aws_iam_role.codebuild_role.name policy_arn = aws_iam_policy.codebuild_s3_access_policy.arn } #------------------------------------------------------------# # code build atached ecr push policy #------------------------------------------------------------# resource \u0026#34;aws_iam_policy\u0026#34; \u0026#34;codebuild_ecr_push_policy\u0026#34; { name = \u0026#34;codebuild-ecr-push-policy-${terraform.workspace}\u0026#34; description = \u0026#34;codebuild_ecr_push_policy\u0026#34; policy = \u0026lt;\u0026lt;EOT { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;ecr\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ecr:BatchCheckLayerAvailability\u0026#34;, \u0026#34;ecr:CompleteLayerUpload\u0026#34;, \u0026#34;ecr:GetAuthorizationToken\u0026#34;, \u0026#34;ecr:InitiateLayerUpload\u0026#34;, \u0026#34;ecr:PutImage\u0026#34;, \u0026#34;ecr:UploadLayerPart\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } EOT } resource \u0026#34;aws_iam_role_policy_attachment\u0026#34; \u0026#34;codebuild_ecr_push_policy\u0026#34; { role = aws_iam_role.codebuild_role.name policy_arn = aws_iam_policy.codebuild_ecr_push_policy.arn } buildspec yal ã®é…ç½® ã“ã®è¾ºã‚’å‚è€ƒã«ã—ã¦ä½œæˆã—ã¦é…ç½® https://docs.aws.amazon.com/ja_jp/codebuild/latest/userguide/sample-docker.html BitBucket ã‹ã‚‰ codebuild ã‚’å®Ÿè¡Œã™ã‚‹ç”¨ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆ #!/bin/bash env=$1 # codebuildã®å®Ÿè¡Œçµæœã‚’å–å¾—ã™ã‚‹ build_output=$(aws codebuild start-build --project-name nnslink-ecr-build-${env}) build_id=$(echo \u0026#34;$build_output\u0026#34; | jq -r \u0026#39;.build.id\u0026#39;) count=0 while : ; do # codebuildã®çŠ¶æ…‹ã‚’å–å¾—ã™ã‚‹ build_status=$(aws codebuild batch-get-builds --ids $build_id --query \u0026#39;builds[0].[buildStatus]\u0026#39; --output text) if [ \u0026#34;$build_status\u0026#34; = \u0026#34;SUCCEEDED\u0026#34; ]; then echo \u0026#34;done!\u0026#34; break elif [ \u0026#34;$build_status\u0026#34; = \u0026#34;FAILED\u0026#34; ]; then exit 1 fi # 10åˆ†ä»¥ä¸Šã‹ã‹ã£ãŸã‚‰å¤±æ•—æ‰±ã„ã§çµ‚äº† count=$((count+1)) if [ $count -gt 20 ]; then echo \u0026#34;[timeout] check aws codebuild console for more detail.\u0026#34; exit 1 fi echo \u0026#34;prosessing...\u0026#34; sleep 30 done exit 0 BitbucketPipeline ã®è¨­å®š definitions: steps: - step: \u0026amp;ECR-push name: ECR push image: atlassian/pipelines-awscli:latest trigger: manual oidc: true script: - export AWS_WEB_IDENTITY_TOKEN_FILE=$(pwd)/web-identity-token - echo $BITBUCKET_STEP_OIDC_TOKEN \u0026gt; $(pwd)/web-identity-token - aws s3 sync ${BITBUCKET_CLONE_DIR}/image/ s3://bucketname/buildspec/ --delete - /bin/bash ./scripts/codebuild.sh ${ENV} pipelines: custom: image-update: - step: \u0026lt;\u0026lt;: *ECR-push deployment: Staging - step: \u0026lt;\u0026lt;: *ECR-push deployment: Production ","permalink":"https://h-neco.github.io/blog/aws-codebuild/","tags":["AWS"],"title":"codebuildæ§‹ç¯‰ã¨deployãƒ•ãƒ­ãƒ¼ã®æ•´å‚™"},{"categories":null,"contents":"Intro EFS ãƒãƒ¼ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã®ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆæ¯æ¸‡å¯¾ç­–ãƒ¡ãƒ¢ EFS ã‚’ãƒãƒ¼ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã§ä½¿ç”¨ã—ã¦ã„ã¦ã€ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆãŒä¸è¶³ã—ã¦ããŸãŸã‚ã€ç§ãŒå–ã£ãŸå¯¾ç­–ã‚’ãƒ¡ãƒ¢ã¨ã—ã¦æä¾›ã—ã¾ã™ã€‚ æŠ€è¡“è¦ç´  EFS aws EFS ã® 2 ã¤ã®ãƒ¢ãƒ¼ãƒ‰ EFS ã«ã¯ 2 ã¤ã®ãƒ¢ãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã™: ãƒãƒ¼ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ï¼ˆæ±ç”¨ï¼‰ã¨ãƒ—ãƒ­ãƒ“ã‚¸ãƒ§ãƒ³ãƒ‰ãƒ¢ãƒ¼ãƒ‰ã€‚\nãƒãƒ¼ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã¯ã€ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã®é‡ã«åŸºã¥ã„ã¦ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã‚’è‡ªå‹•çš„ã«èª¿æ•´ã—ã€ä¸€æ™‚çš„ãªãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã®å¢—åŠ ã«å¯¾å¿œã§ãã¾ã™ã€‚ãƒãƒ¼ã‚¹ãƒˆå¯èƒ½ãªå¸¯åŸŸå¹…ã¯ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã®ä½¿ç”¨çŠ¶æ³ã«ã‚ˆã£ã¦ç•°ãªã‚Šã€æœ€ä½ 105 Mbps ã®ãƒãƒ¼ã‚¹ãƒˆãŒå¯èƒ½ã§ã™ã€‚ãŸã ã—ã€1 ç§’ã‚ãŸã‚Šã®èª­ã¿å–ã‚Š/æ›¸ãè¾¼ã¿ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®æ•°ã«ã¯åˆ¶é™ãŒã‚ã‚Šã€åˆ¶é™ã‚’è¶…ãˆã‚‹ã¨ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆãŒä½ä¸‹ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\nãƒ—ãƒ­ãƒ“ã‚¸ãƒ§ãƒ³ãƒ‰ãƒ¢ãƒ¼ãƒ‰ã§ã¯ã€ãƒœãƒªãƒ¥ãƒ¼ãƒ ã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã€æœ€å°/æœ€å¤§/ãƒãƒ¼ã‚¹ãƒˆã€ãŠã‚ˆã³æ›¸ãè¾¼ã¿ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’è¨­å®šã§ãã¾ã™ã€‚èª­ã¿å–ã‚Šã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã¯æ›¸ãè¾¼ã¿ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã® 3 å€ã§ã™ã€‚ãƒ—ãƒ­ãƒ“ã‚¸ãƒ§ãƒ³ãƒ‰ãƒ¢ãƒ¼ãƒ‰ã¯ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã«åŸºã¥ã„ãŸè‡ªå‹•ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã¯ã‚ã‚Šã¾ã›ã‚“ãŒã€ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã®è¨­å®šã«åŸºã¥ã„ã¦å¿…è¦ãªãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯ã«å¯¾å¿œã§ãã¾ã™ã€‚\nãƒãƒ¼ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ï¼ˆæ±ç”¨ï¼‰ã®æ³¨æ„äº‹é …ã¨å¯¾ç­– ãƒãƒ¼ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ï¼ˆæ±ç”¨ï¼‰ã®æ³¨æ„äº‹é …ã¨å¯¾ç­–\næ³¨æ„äº‹é … 1: ãƒãƒ¼ã‚¹ãƒˆã‚¯ãƒ¬ã‚¸ãƒƒãƒˆ\nãƒãƒ¼ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã¯ã€ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿å–ã‚Š/æ›¸ãè¾¼ã¿æ“ä½œã‹ã‚‰è“„ç©ã•ã‚ŒãŸã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚’æ¶ˆè²»ã—ã€NAS ä¸Šã®ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨çŠ¶æ³ã«åŸºã¥ã„ã¦ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚’è£œå……ã—ã¾ã™ã€‚ãƒãƒ¼ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã®æœ€ä½é€Ÿåº¦ã¯ 105 Mbps ã§ã™ã€‚ãŸã ã—ã€ãƒãƒ¼ã‚¹ãƒˆã‚¯ãƒ¬ã‚¸ãƒƒãƒˆãŒæ¯æ¸‡ã™ã‚‹ã¨ã€ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã®æ€§èƒ½ãŒè‘—ã—ãä½ä¸‹ã—ã€ãƒã‚¦ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰ã®ãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã™ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚\nç¢ºèªæ–¹æ³•:\nãƒ¡ãƒˆãƒªãƒƒã‚¯å: BurstCreditBalance æœ€åˆã« 2.3T ã®ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆãŒæä¾›ã•ã‚Œã¾ã™ã€‚ ãƒãƒ¼ã‚¹ãƒˆã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã®æ¯æ¸‡ã‚’é¿ã‘ã‚‹ãŸã‚ã«ã¯ã€ä»¥ä¸‹ã®å¯¾ç­–ã‚’å–ã‚‹ã“ã¨ãŒã§ãã¾ã™:\nã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã®å›å¾©ã‚’åŠ é€Ÿã™ã‚‹ãŸã‚ã«å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚’é…ç½®ã™ã‚‹ã€‚ ãƒ—ãƒ­ãƒ“ã‚¸ãƒ§ãƒ³ãƒ‰ãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆã¦ä¸€å®šã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’ç¢ºä¿ã™ã‚‹ã€‚ æ³¨æ„äº‹é … 2: ãƒªã‚¯ã‚¨ã‚¹ãƒˆåˆ¶é™\nãƒãƒ¼ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã«ã¯ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®åˆ¶é™ãŒã‚ã‚Šã¾ã™ã€‚ ãƒªãƒ¼ãƒ‰ç”¨ã®æœ€å¤§ IOPS ã¯ 35,000ã€ãƒ©ã‚¤ãƒˆç”¨ã®æœ€å¤§ IOPS ã¯ 7,000 ã§ã™ã€‚ ãƒãƒ¼ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã®æœ€å¤§ IOPS ã‚’è¶…ãˆã‚‹ã¨ã€ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒä½ä¸‹ã—ã¾ã™ã€‚ã—ãŸãŒã£ã¦ã€é«˜ã„ IOPS ãŒå¿…è¦ãªå ´åˆã¯ã€ãƒ—ãƒ­ãƒ“ã‚¸ãƒ§ãƒ³ãƒ‰ãƒ¢ãƒ¼ãƒ‰ã®ä½¿ç”¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚ ç¢ºèªæ–¹æ³•: ãƒ¡ãƒˆãƒªãƒƒã‚¯å: PercentIOLimit æ¤œè¨ã«åŸºã¥ãå¯¾ç­–ã®å–å¾— ãƒãƒ¼ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã«å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ã‚’é…ç½®ã—ã¦ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã®å›å¾©é€Ÿåº¦ã‚’åŠ é€Ÿã™ã‚‹ã¨ã„ã†æˆ¦ç•¥ã‚’æ¡ç”¨ã—ã¾ã—ãŸã€‚\n10GB ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ç½®ã™ã‚‹è©¦ã¿ã€‚ ã‚³ã‚¹ãƒˆ: $3/æœˆ ã‚³ãƒãƒ³ãƒ‰: $ dd if=/dev/zero of=10GB_file_1 bs=10240k count=1000 ç¢ºèªæ–¹æ³•: ãƒ¡ãƒˆãƒªãƒƒã‚¯å: BurstCreditBalance é«˜ã„ã‚³ã‚¹ãƒˆã®ãŸã‚ã€ãƒ—ãƒ­ãƒ“ã‚¸ãƒ§ãƒ³ãƒ‰ãƒ¢ãƒ¼ãƒ‰ã¯ä½¿ç”¨ã—ã¦ã„ã¾ã›ã‚“ã€‚ ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ 33(Mib/s) / æœ€å¤§èª­ã¿å–ã‚Šã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ 99(Mib/s) ã‚³ã‚¹ãƒˆ: $238/æœˆ ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ 15(Mib/s) / æœ€å¤§èª­ã¿å–ã‚Šã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ 45(Mib/s) ã‚³ã‚¹ãƒˆ: $108/æœˆ ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ 5(Mib/s) / æœ€å¤§èª­ã¿å–ã‚Šã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ 15(Mib/s) ã‚³ã‚¹ãƒˆ: $36/æœˆ ","permalink":"https://h-neco.github.io/blog/aws-efs/","tags":["AWS"],"title":"EFS Burst Mode ã®ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆæ¯æ¸‡å¯¾ç­–ãƒ¡ãƒ¢"},{"categories":null,"contents":"Intro ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯ã€EC2 ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãŒçµ‚äº†ã™ã‚‹ã¨ã€ã‚¢ã‚¿ãƒƒãƒã•ã‚ŒãŸ EBS ãƒœãƒªãƒ¥ãƒ¼ãƒ ã‚‚å‰Šé™¤ã•ã‚Œã¾ã™ã€‚ã—ã‹ã—ã€AWS CLI ã‚’ä½¿ç”¨ã—ã¦ã“ã‚Œã‚‰ã‚’æ°¸ç¶šåŒ–ã™ã‚‹æ–¹æ³•ã‚’æ¢ã£ã¦ã¿ã¾ã—ã‚‡ã†ã€‚ æŠ€è¡“è¦ç´  EC2/EBS ã‚³ãƒãƒ³ãƒ‰ ã‚¿ã‚°ã«ã‚ˆã£ã¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸå¯¾è±¡ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ãƒœãƒªãƒ¥ãƒ¼ãƒ æƒ…å ±ã‚’å–å¾—ã—ã¾ã™ã€‚ DeleteOnTermination ãŒ true ã§ã‚ã‚‹å ´åˆã€ãƒœãƒªãƒ¥ãƒ¼ãƒ ã¯æ°¸ç¶šåŒ–ã•ã‚Œã¦ã„ãªã„ã“ã¨ã‚’æ„å‘³ã—ã¾ã™ã€‚ $ aws ec2 describe-instances --filters \u0026#34;Name=tag:Name,Values=xxxxx-prod-web01\u0026#34; | jq -r .Reservations[0].Instances[0].BlockDeviceMappings [ { \u0026#34;DeviceName\u0026#34;: \u0026#34;/dev/sda1\u0026#34;, \u0026#34;Ebs\u0026#34;: { \u0026#34;AttachTime\u0026#34;: \u0026#34;2023-04-18T04:59:14+00:00\u0026#34;, \u0026#34;DeleteOnTermination\u0026#34;: true, \u0026#34;Status\u0026#34;: \u0026#34;attached\u0026#34;, \u0026#34;VolumeId\u0026#34;: \u0026#34;vol-xxxxxxxxxxxx\u0026#34; } } ] è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’æº–å‚™ã—ã¾ã™ã€‚ DeleteOnTermination ã‚’ false ã«è¨­å®šã—ã¾ã™ã€‚ $ vim mapping.json [ { \u0026#34;DeviceName\u0026#34;: \u0026#34;/dev/sda1\u0026#34;, \u0026#34;Ebs\u0026#34;: { \u0026#34;DeleteOnTermination\u0026#34;: false } } ] ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®è¨­å®šå¤‰æ›´ $ aws ec2 modify-instance-attribute --instance-id \u0026#34;i-xxxxxxxxxxxxxx\u0026#34; --block-device-mappings file://mapping.json ã‚¿ã‚°ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸå¯¾è±¡ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ãƒœãƒªãƒ¥ãƒ¼ãƒ æƒ…å ±ã‚’å–å¾—ã—ã¾ã™ã€‚ DeleteOnTermination ãŒ false ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¾ã™ã€‚ $ aws ec2 describe-instances --filters \u0026#34;Name=tag:Name,Values=xxxxx-prod-web01\u0026#34; | jq -r .Reservations[0].Instances[0].BlockDeviceMappings [ { \u0026#34;DeviceName\u0026#34;: \u0026#34;/dev/sda1\u0026#34;, \u0026#34;Ebs\u0026#34;: { \u0026#34;AttachTime\u0026#34;: \u0026#34;2023-04-18T04:59:14+00:00\u0026#34;, \u0026#34;DeleteOnTermination\u0026#34;: false, \u0026#34;Status\u0026#34;: \u0026#34;attached\u0026#34;, \u0026#34;VolumeId\u0026#34;: \u0026#34;vol-xxxxxxxxxxxx\u0026#34; } } ] ","permalink":"https://h-neco.github.io/blog/aws-ec2-ebs-delete-on-termination/","tags":["AWS"],"title":"Persisting an Attached EBS Volume to EC2 Using AWS CLI."},{"categories":null,"contents":"Intro ä»¥å‰ã¯ã€GitHub ã‚„ Bitbucket ã‹ã‚‰å€‹äººã® AWS ã¸ã®ãƒ‡ãƒ—ãƒ­ã‚¤æ™‚ã«ã‚¢ã‚¯ã‚»ã‚¹ã‚­ãƒ¼ã¨ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‚­ãƒ¼ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã—ãŸã€‚ã—ã‹ã—ã€ã“ã‚Œã‚’ç®¡ç†ã™ã‚‹ã®ãŒç…©é›‘ã«ãªã£ãŸãŸã‚ã€OIDC ã«åˆ‡ã‚Šæ›¿ãˆã¾ã—ãŸã€‚\nOIDC (OpenID Connect) ã¯ã€èªè¨¼ã¨èªå¯ã®ãŸã‚ã®ã‚ªãƒ¼ãƒ—ãƒ³ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰ã§ã™ã€‚OIDC ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€AWS ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’å®‰å…¨ã«ç®¡ç†ã—ã€èªè¨¼ãƒ—ãƒ­ãƒã‚¤ãƒ€ã‚’ä»‹ã—ã¦ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ãªã‚¢ã‚¯ã‚»ã‚¹ä½“é¨“ã‚’æä¾›ã§ãã¾ã™ã€‚OIDC ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã€AWS ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã«ã¯ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³ãŒä½¿ç”¨ã•ã‚Œã¾ã™ã€‚\nOIDC ã‚’å°å…¥ã™ã‚‹ã“ã¨ã§ã€ã‚¢ã‚¯ã‚»ã‚¹ã‚­ãƒ¼ã‚„ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‚­ãƒ¼ã‚’å€‹åˆ¥ã«ç®¡ç†ã™ã‚‹å¿…è¦ãŒãªããªã‚Šã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¨åˆ©ä¾¿æ€§ãŒå‘ä¸Šã—ã¾ã™ã€‚\nã‚„ã‚‹ã“ã¨ Terraform ã§ OIDC ã‚’è¨­å®šã™ã‚‹æ–¹æ³• GitHub Bitbucket OIDC ã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹æ–¹æ³• ã‚·ãƒ³ãƒ—ãƒ«ãª GitHub Actions ã¨ Bitbucket Pipelines ã®ä½œæˆ æŠ€è¡“è¦ç´  OIDC AWS Bitbucket GitHub Terraform What is OIDC? OIDCï¼ˆOpenID Connectï¼‰ã¯ã€OAuth 2.0 ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’æ‹¡å¼µã—ã€Web ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚„ãƒ¢ãƒã‚¤ãƒ«ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã«ãŠã‘ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼èªè¨¼ã®ä»•çµ„ã¿ã‚’æä¾›ã™ã‚‹èªè¨¼ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã§ã™ã€‚\nBenefits of OIDC Git ã‹ã‚‰ã®ãƒ‡ãƒ—ãƒ­ã‚¤ã« OIDC ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€ã„ãã¤ã‹ã®åˆ©ç‚¹ãŒã‚ã‚Šã¾ã™ã€‚ãã‚Œã«ã¯ã€Git ã‚’ä»‹ã—ãŸãƒ‡ãƒ—ãƒ­ã‚¤ã®ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®å‘ä¸Šã€ãƒˆãƒ¼ã‚¯ãƒ³ã®æœ‰åŠ¹æœŸé™ã®ç®¡ç†ã®å®¹æ˜“åŒ–ã€MFA ãŒæœ‰åŠ¹åŒ–ã•ã‚Œã¦ã„ãªã„ã‚¢ã‚¯ã‚»ã‚¹ã‚­ãƒ¼ã®ä½¿ç”¨ã«é–¢é€£ã™ã‚‹ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯ã®å›é¿ãªã©ãŒã‚ã‚Šã¾ã™ã€‚ãŸã ã—ã€MFA ãŒæœ‰åŠ¹åŒ–ã•ã‚ŒãŸã‚¢ã‚¯ã‚»ã‚¹ã‚­ãƒ¼ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯ã€ãƒ‡ãƒã‚¤ã‚¹ç®¡ç†ãªã©ã®è¦ç´ ã‚’è€ƒæ…®ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ãŸã‚ã€è¤‡é›‘ãªå ´åˆãŒã‚ã‚Šã¾ã™ã€‚OIDC ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ ID ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®èªè¨¼è³‡æ ¼æƒ…å ±ã‚’ä½¿ç”¨ã§ãã‚‹ãŸã‚ã€èªè¨¼æƒ…å ±ã®ç®¡ç†ãŒç°¡ç´ åŒ–ã•ã‚Œã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãŒå‘ä¸Šã—ã¾ã™ã€‚\næ§‹ç¯‰èƒŒæ™¯ ä»¥å‰ã¯ã€AWS ã¸ã®ãƒ‡ãƒ—ãƒ­ã‚¤ã¯æ‰‹é–“ãŒã‹ã‹ã‚‹ã‚‚ã®ã§ã—ãŸã€‚CLI ã®ä»£ã‚ã‚Šã«ç®¡ç†ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã‹ã‚‰ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹ã“ã¨ã‚’è€ƒãˆã‚‹ã»ã©ã§ã™ã€‚\nä»¥å‰ã®ãƒ•ãƒ­ãƒ¼ã§ã¯ã€ã‚­ãƒ¼ã®å–å¾—ã«ä¸ä¾¿ã•ãŒä¼´ã„ã¾ã—ãŸï¼š ã‚¢ãƒ—ãƒªã‹ã‚‰ MFA ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç¢ºèªã—ã¦ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹ï¼š $ aws sts get-session-token \u0026ndash;serial-number arn:aws:iam::xxxxxx:mfa/xxxxxx \u0026ndash;token-code xxxxxx å–å¾—ã—ãŸã‚­ãƒ¼ã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹ã‹ã€Git ã«ç™»éŒ²ã™ã‚‹ ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®æœ‰åŠ¹æœŸé™ãŒåˆ‡ã‚Œã‚‹ãŸã³ã«å®šæœŸçš„ã«ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹\u0026hellip; Terraform ã§ OIDC ã‚’æ§‹ç¯‰ã™ã‚‹ Terraform ã§ã®æ§‹ç¯‰ GitHub Actions ã‚’ä½¿ç”¨ã™ã‚‹ã‚·ãƒŠãƒªã‚ªã¨ Bitbucket Pipelines ã‚’ä½¿ç”¨ã™ã‚‹ã‚·ãƒŠãƒªã‚ªã® 2 ã¤ã‚’èª¬æ˜ã—ã¾ã™ã€‚ GitHub Sample variable \u0026#34;aws_account_id\u0026#34; {} variable \u0026#34;github_repo_name\u0026#34; {} variable \u0026#34;oidc_token_url\u0026#34; { default = \u0026#34;https://token.actions.githubusercontent.com\u0026#34; } data \u0026#34;tls_certificate\u0026#34; \u0026#34;github_oidc_token\u0026#34; { url = var.oidc_token_url } resource \u0026#34;aws_iam_openid_connect_provider\u0026#34; \u0026#34;github_oidc_provider\u0026#34; { url = var.oidc_token_url client_id_list = [ \u0026#34;sts.amazonaws.com\u0026#34; ] thumbprint_list = [data.tls_certificate.github_oidc_token.certificates.0.sha1_fingerprint] } data \u0026#34;aws_iam_policy_document\u0026#34; \u0026#34;github_oidc_policy\u0026#34; { statement { actions = [\u0026#34;sts:AssumeRoleWithWebIdentity\u0026#34;] effect = \u0026#34;Allow\u0026#34; principals { type = \u0026#34;Federated\u0026#34; identifiers = [\u0026#34;arn:aws:iam::${var.aws_account_id}:oidc-provider/oidc-provider/token.actions.githubusercontent.com\u0026#34;] } condition { test = \u0026#34;StringEquals\u0026#34; variable = \u0026#34;token.actions.githubusercontent.com:sub\u0026#34; values = [\u0026#34;repo:${var.github_repo_name}:ref:refs/heads/main\u0026#34;] } } } resource \u0026#34;aws_iam_role\u0026#34; \u0026#34;github_oidc_role\u0026#34; { name = \u0026#34;GithubOIDC-TEST\u0026#34; description = \u0026#34;GithubOIDC-TEST\u0026#34; assume_role_policy = data.aws_iam_policy_document.github_oidc_policy.json } resource \u0026#34;aws_iam_role_policy_attachment\u0026#34; \u0026#34;github_oidc_administrator_access_attachment\u0026#34; { role = aws_iam_role.github_oidc_role.name policy_arn = \u0026#34;arn:aws:iam::aws:policy/AdministratorAccess\u0026#34; } Bitbucket Sample variable \u0026#34;bitbucket_oidc_url\u0026#34; {} variable \u0026#34;bitbucket_oidc_audience\u0026#34; {} variable \u0026#34;account_id\u0026#34; {} variable \u0026#34;git_space\u0026#34; {} data \u0026#34;tls_certificate\u0026#34; \u0026#34;bitbucket\u0026#34; { url = var.bitbucket_oidc_url } resource \u0026#34;aws_iam_openid_connect_provider\u0026#34; \u0026#34;bitbucket\u0026#34; { url = var.bitbucket_oidc_url client_id_list = [ var.bitbucket_oidc_audience, ] thumbprint_list = [data.tls_certificate.bitbucket.certificates.0.sha1_fingerprint] } data \u0026#34;aws_iam_policy_document\u0026#34; \u0026#34;bitbucket_oidc_policy\u0026#34; { statement { actions = [\u0026#34;sts:AssumeRoleWithWebIdentity\u0026#34;] effect = \u0026#34;Allow\u0026#34; principals { type = \u0026#34;Federated\u0026#34; identifiers = [\u0026#34;arn:aws:iam::${var.account_id}:oidc-provider/api.bitbucket.org/2.0/workspaces/${var.git_space}/pipelines-config/identity/oidc\u0026#34;] } condition { test = \u0026#34;StringEquals\u0026#34; variable = \u0026#34;api.bitbucket.org/2.0/workspaces/${var.git_space}/pipelines-config/identity/oidc:aud\u0026#34; values = [var.bitbucket_oidc_audience] } } } resource \u0026#34;aws_iam_role\u0026#34; \u0026#34;bitbucket_oidc_role\u0026#34; { name = \u0026#34;BitbucketOIDC-TEST\u0026#34; description = \u0026#34;BitbucketOIDC-TEST\u0026#34; assume_role_policy = data.aws_iam_policy_document.bitbucket_oidc_policy.json } resource \u0026#34;aws_iam_role_policy_attachment\u0026#34; \u0026#34;administrator_access_attachment\u0026#34; { role = aws_iam_role.bitbucket_oidc_role.name policy_arn = \u0026#34;arn:aws:iam::aws:policy/AdministratorAccess\u0026#34; } Testing OIDC Setup Github Action The sample code deploys statically built Hugo content to S3 using OIDC. name: s3-deploy on: push: branches: - main jobs: s3put: runs-on: ubuntu-latest permissions: id-token: write contents: read steps: - name: Checkout code uses: actions/checkout@v2 - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#39;0.111.3\u0026#39; - name: Build run: hugo --minify - uses: aws-actions/configure-aws-credentials@v1 with: aws-region: \u0026#39;ap-northeast-1\u0026#39; # Specify the region role-to-assume: \u0026#39;arn:aws:iam::xxxxxxxxxxx:role/oidc-role\u0026#39; # ARN of the created IAM role - name: Deploy run: aws s3 sync --delete public s3://my-s3-bucket/ Bitbucket Pipelines The sample code syncs the \u0026ldquo;public\u0026rdquo; folder from the master branch to my-s3-bucket using OIDC. image: amazon/aws-cli pipelines: default: - step: \u0026amp;s3-deploy name: Deploy to S3 with OIDC oidc: true script: - export AWS_WEB_IDENTITY_TOKEN_FILE=$(pwd)/web-identity-token - export AWS_ROLE_ARN=\u0026#39;created role\u0026#39; - echo $BITBUCKET_STEP_OIDC_TOKEN \u0026gt; $(pwd)/web-identity-token - aws s3 sync --delete public s3://my-s3-bucket/ branches: master: - step: *s3-deploy Setting up OIDC with CloudFormation Parameters: AwsAccountId: Type: String Description: AWS Account ID GithubRepoName: Type: String Description: Name of the GitHub repository OidcTokenUrl: Type: String Default: https://token.actions.githubusercontent.com Resources: GithubOidcTokenCertificate: Type: AWS::CloudFormation::CustomResource Version: \u0026#34;1.0\u0026#34; Properties: ServiceToken: !Sub arn:aws:lambda:${AWS::Region}:${AWS::AccountId}:function:token-actions-github Url: !Ref OidcTokenUrl GithubOidcProvider: Type: AWS::IAM::OpenIDConnectProvider Properties: Url: !Ref OidcTokenUrl ClientIDList: - sts.amazonaws.com ThumbprintList: - !GetAtt GithubOidcTokenCertificate.Sha1Fingerprint GithubOidcPolicyDocument: Type: AWS::IAM::Policy Properties: PolicyName: GithubOIDCPolicy PolicyDocument: Version: \u0026#34;2012-10-17\u0026#34; Statement: - Effect: Allow Action: sts:AssumeRoleWithWebIdentity Resource: \u0026#34;*\u0026#34; Condition: StringEquals: token.actions.githubusercontent.com:sub: - !Sub \u0026#34;repo:${GithubRepoName}:ref:refs/heads/main\u0026#34; Principal: Federated: !Sub arn:aws:iam::${AwsAccountId}:oidc-provider/oidc-provider/token.actions.githubusercontent.com GithubOidcRole: Type: AWS::IAM::Role Properties: RoleName: GithubOIDC-TEST AssumeRolePolicyDocument: !Ref GithubOidcPolicyDocument GithubOidcAdministratorAccessAttachment: Type: AWS::IAM::PolicyAttachment Properties: PolicyArn: arn:aws:iam::aws:policy/AdministratorAccess Roles: - !Ref GithubOidcRole ","permalink":"https://h-neco.github.io/blog/cicd-oidc/","tags":["DevOps"],"title":"OIDCã§ã®ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ¢ (Git to AWS)"},{"categories":null,"contents":"Intro PC ã®å…¥ã‚Œæ›¿ãˆã«ä¼´ã„ã€Lambda ã®ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œç’°å¢ƒã‚’å†æ§‹ç¯‰ã—ãŸã€‚ãƒ¡ãƒ¢ã¨ã—ã¦æ®‹ã—ã¦ãŠãã¾ã™ã€‚ PC ãƒªãƒ—ãƒ¬ãƒ¼ã‚¹ã®ã¤ã„ã§ã« Lambda ã®ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œç’°å¢ƒã‚’å†æ§‹ç¯‰ã€‚ãƒ¡ãƒ¢ã¨ã—ã¦æ®‹ã—ã¦ãŠãã€‚\næŠ€è¡“è¦ç´  Volta Lambda LocalStack TypeScript SAM å‰ææ¡ä»¶ Installing Volta Volta ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« Volta ã¯ Node.js ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã«ç‰¹åŒ–ã—ãŸãƒ„ãƒ¼ãƒ«ã§ã™ã€‚ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã”ã¨ã«ç•°ãªã‚‹ Node.js ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹ã“ã¨ãŒã§ãã€Node.js ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’æ‰‹å‹•ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒ»ç®¡ç†ã™ã‚‹ã“ã¨ãªãã€ç•°ãªã‚‹ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç°¡å˜ã«ç®¡ç†ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚Volta ã¯ã€ä»–ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ãƒ„ãƒ¼ãƒ«ã¨æ¯”è¼ƒã—ã¦åˆ‡ã‚Šæ›¿ãˆãŒç°¡å˜ã¨ã„ã†åˆ©ç‚¹ãŒã‚ã‚Šã€OS ã‚„ã‚·ã‚§ãƒ«ã«ä¾å­˜ã—ãªã„ãŸã‚æ§˜ã€…ãªç’°å¢ƒã§åˆ©ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\n$ curl https://get.volta.sh | bash $ echo \u0026#39;export VOLTA_HOME=\u0026#34;$HOME/.volta\u0026#34;\u0026#39; \u0026gt;\u0026gt; .zshrc $ echo \u0026#39;export PATH=\u0026#34;$VOLTA_HOME/bin:$PATH\u0026#34;\u0026#39; \u0026gt;\u0026gt; .zshrc Node.js ã¨ Yarn ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« åˆ©ç”¨å¯èƒ½ãªãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç¢ºèªã™ã‚‹ã«ã¯ã€volta list node ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ç‰¹å®šã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ãŸã„å ´åˆã¯ã€volta install node@18.15.0 ã¨ã„ã†ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ä½¿ã£ã¦ãã ã•ã„ã€‚\n$ volta install node success: installed and set node@18.15.0 (with npm@9.5.0) as default $ volta install yarn success: installed and set yarn@4.0.0-rc.42 as default SAM ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« ä»¥ä¸‹ã®æ‰‹é †ã¯ macOS ç”¨ã§ã‚ã‚‹ã€‚Windows ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ–¹ã¯å…¬å¼ã‚µã‚¤ãƒˆã‹ã‚‰ MSI ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚\nmacOS $ brew tap aws/tap $ brew install aws-sam-cli $ sam --version SAM CLI, version 1.78.0 Creating a Project $ sam init -r nodejs18.x SAM CLI now collects telemetry to better understand customer needs. You can OPT OUT and disable telemetry collection by setting the environment variable SAM_CLI_TELEMETRY=0 in your shell. Thanks for your help! Learn More: https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-sam-telemetry.html Which template source would you like to use? 1 - AWS Quick Start Templates 2 - Custom Template Location Choice: 1 Choose an AWS Quick Start application template 1 - Hello World Example 2 - Hello World Example With Powertools 3 - Multi-step workflow 4 - Standalone function 5 - Scheduled task 6 - Data processing 7 - Serverless API Template: 1 Based on your selections, the only Package type available is Zip. We will proceed to selecting the Package type as Zip. Based on your selections, the only dependency manager available is npm. We will proceed copying the template using npm. Select your starter template 1 - Hello World Example 2 - Hello World Example TypeScript Template: 2 Would you like to enable X-Ray tracing on the function(s) in your application? [y/N]: n Would you like to enable monitoring using CloudWatch Application Insights? For more info, please view https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch-application-insights.html [y/N]: n Project name [sam-app]: sam-local-study Cloning from https://github.com/aws/aws-sam-cli-app-templates (process may take a moment) ----------------------- Generating application: ----------------------- Name: sam-local-study Runtime: nodejs18.x Architectures: x86_64 Dependency Manager: npm Application Template: hello-world-typescript Output Directory: . Configuration file: sam-local-study/samconfig.toml Next steps can be found in the README file at sam-local-study/README.md Commands you can use next ========================= [*] Create pipeline: cd sam-local-study \u0026amp;\u0026amp; sam pipeline init --bootstrap [*] Validate SAM template: cd sam-local-study \u0026amp;\u0026amp; sam validate [*] Test Function in the Cloud: cd sam-local-study \u0026amp;\u0026amp; sam sync --stack-name {stack-name} --watch ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¾“ã†ã¨ã€ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒç”Ÿæˆã•ã‚Œã‚‹ï¼š\n$ tree . . â””â”€â”€ sam-local-study â”œâ”€â”€ README.md â”œâ”€â”€ events â”‚Â â””â”€â”€ event.json â”œâ”€â”€ hello-world â”‚Â â”œâ”€â”€ app.ts â”‚Â â”œâ”€â”€ jest.config.ts â”‚Â â”œâ”€â”€ package.json â”‚Â â”œâ”€â”€ tests â”‚Â â”‚Â â””â”€â”€ unit â”‚Â â”‚Â â””â”€â”€ test-handler.test.ts â”‚Â â””â”€â”€ tsconfig.json â”œâ”€â”€ samconfig.toml â””â”€â”€ template.yaml 6 directories, 9 files ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã™ã‚µãƒ³ãƒ—ãƒ« Lambda é–¢æ•°ã®ä½œæˆ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿”ã™ Lambda é–¢æ•°ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’ä½œæˆã—ã€SAM ã‚’ä½¿ã£ã¦å®Ÿè¡Œã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚\nã‚³ãƒ¼ãƒ‰ã®æº–å‚™ $ tree . . â””â”€â”€ sam-local-study â”œâ”€â”€ src â”‚ â”œâ”€â”€ handlers â”‚ â””â”€â”€ hello-from-lambda.js â””â”€â”€ template.yaml src/handlers/hello-from-lambda.js exports.helloFromLambdaHandler = async () =\u0026gt; { const message = \u0026#34;Hello from Lambda!\u0026#34;; console.info(`${message}`); return message; }; template.yaml Resources: HelloWorldFunction: Type: AWS::Serverless::Function Properties: Handler: src/handlers/hello-from-lambda.helloFromLambdaHandler Runtime: nodejs18.x MemorySize: 128 Timeout: 100 Description: A Lambda function that returns a static string. Policies: - AWSLambdaBasicExecutionRole \u0026ldquo;Hello \u0026ldquo;ã‚’è¿”ã™ãƒ©ãƒ ãƒ€é–¢æ•°ã®å®Ÿè¡Œ Execute the command: $ sam local invoke HelloWorldFunction Output: Invoking src/handlers/hello-from-lambda.helloFromLambdaHandler (nodejs18.x) Local image is up-to-date Using local image: public.ecr.aws/lambda/nodejs:18-rapid-x86_64. Mounting /lambda-sam-localstack/sam-local-study as /var/task:ro,delegated, inside runtime container START RequestId: 6d2615de-b38f-4300-bf87-704e1fa6296a Version: $LATEST 2023-04-05T08:41:27.339Z\t6d2615de-b38f-4300-bf87-704e1fa6296a\tINFO\tHello from Lambda! END RequestId: 6d2615de-b38f-4300-bf87-704e1fa6296a REPORT RequestId: 6d2615de-b38f-4300-bf87-704e1fa6296a\tInit Duration: 0.75 ms\tDuration: 953.12 ms\tBilled Duration: 954 ms\tMemory Size: 128 MB\tMax Memory Used: 128 MB \u0026#34;Hello from Lambda!\u0026#34;% LocalStack ã‚’ä½¿ã† ã‚¯ãƒ¬ãƒ‡ãƒ³ã‚·ãƒ£ãƒ«ã®è¨­å®š (~/.aws/credentials) [localstack] aws_access_key_id = dummy aws_secret_access_key = dummy docker-compose.yml ã‚’ç”¨æ„ã™ã‚‹ docker-compose.yml ã‚’ä½¿ã£ã¦ LocalStack ã‚’èµ·å‹•ã™ã‚‹ ã‚³ãƒãƒ³ãƒ‰ï¼šdocker-compose up -d version: \u0026#39;3.7\u0026#39; services: localstack: image: localstack/localstack ports: - \u0026#39;4566:4566\u0026#39; environment: - SERVICES=s3,dynamodb - PERSISTENCE=1 volumes: - \u0026#39;${LOCALSTACK_VOLUME_DIR:-./volume}:/var/lib/localstack\u0026#39; networks: - localstack networks: localstack: name: sam-local-localstack SAM ã‚’ä½¿ã£ã¦ LocalStack ã§å®Ÿè¡Œã™ã‚‹ sam local invoke HelloWorldFunction \\ -e events/event.json \\ --docker-network sam-local-localstack \\ --profile localstack ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã‚’ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‹ã‚‰å‚ç…§ã™ã‚‹æ–¹æ³• s3 ã‚’ä½œæˆã™ã‚‹ aws s3 mb s3://xxxxxxxx --endpoint-url http://localhost:4566 --profile localstack ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã‚’ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‹ã‚‰å‚ç…§ã™ã‚‹æ–¹æ³•ã€‚ä¸€éƒ¨æŠœç²‹ const endpoint = env.isLocal ? \u0026#34;http://localstack:4566\u0026#34; : undefined; const s3Client = new S3Client({ apiVersion: \u0026#34;2006-03-01\u0026#34;, endpoint: endpoint, forcePathStyle: env.isLocal ? true : false, }); ","permalink":"https://h-neco.github.io/blog/aws-lambda-local-execution/","tags":["AWS"],"title":"Lambdaãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºç’°å¢ƒæ§‹ç¯‰ãƒ¡ãƒ¢ (SAM | LocalStack | TypeScript)"},{"categories":null,"contents":"Intro Terraform ã® Wrapper ãƒ„ãƒ¼ãƒ«ã€Terragrunt å°å…¥ã®æ¤œè¨¼ã‚’è¡Œã„ã¾ã—ãŸã€‚ å°å…¥ã®æ¤œè¨¼ é€šå¸¸ã€ç§ã¯ Terraform ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ãŒã€æ¬¡ã®ã‚ˆã†ãªä¸ä¾¿ã•ãŒã‚ã‚Šã¾ã—ãŸï¼š å„ãƒ‡ãƒ—ãƒ­ã‚¤ã®å½±éŸ¿ç¯„å›²ã‚’æœ€å°é™ã«æŠ‘ãˆã‚‹ãŸã‚ã«ã€Git ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚ˆã‚Šå°ã•ãªã‚‚ã®ã«åˆ†å‰²ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã—ãŸã€‚Terraform ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚¢ãƒƒãƒ—ãŒé¢å€’ã§ã—ãŸã€‚ ã‚³ãƒ¼ãƒ‰ã‹ã‚‰ãƒªã‚½ãƒ¼ã‚¹ã®ä¾å­˜é–¢ä¿‚ã‚’ç†è§£ã™ã‚‹ã®ãŒé›£ã—ã‹ã£ãŸã§ã™ã€‚ depends_on ãŒæ˜ç¤ºçš„ã«ä½¿ç”¨ã§ããªã„å ´æ‰€ã§ãƒ‡ãƒ—ãƒ­ã‚¤é †åºã«æ³¨æ„ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã—ãŸã€‚ å°å…¥å¾Œã®èª²é¡Œ å°å…¥ã«é–¢ã—ã¦ã€ä»¥ä¸‹ã® 2 ç‚¹ã«ã¤ã„ã¦æ¤œè¨¼ãŒä¿ç•™ã•ã‚Œã¦ã„ã¾ã™ã€‚ã‚‚ã—è©³ã—ã„æ–¹ãŒã„ãŸã‚‰ç›¸è«‡ã«ä¹—ã£ã¦ã„ãŸã ã‘ã‚‹ã¨å¹¸ã„ã§ã™ã€‚ Terraform ã®ç®¡ç†ã ã‘ã§ãªãã€Terragrunt ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã‚‚è¡Œã†å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚¢ãƒƒãƒ—ã®ãƒ—ãƒ­ã‚»ã‚¹ã¯ã©ã®ã‚ˆã†ã«å¤‰ã‚ã‚‹ã®ã‹ ã‚‚ã— Terragrunt ã®é–‹ç™ºãŒåœæ­¢ã—ãŸå ´åˆã€ã‚¹ãƒ ãƒ¼ã‚ºã« Terraform ã®ã‚³ãƒ¼ãƒ‰ã«æˆ»ã›ã‚‹ã‹ æŠ€è¡“è¦ç´  terraform terragrunt aws Terragrunt ã¨ã¯ Terragrunt ã¯ã€Terraform ã‚’ä½¿ç”¨ã—ã¦ã‚¤ãƒ³ãƒ•ãƒ©ã‚¹ãƒˆãƒ©ã‚¯ãƒãƒ£ã‚’ç®¡ç†ã™ã‚‹ãŸã‚ã®ä½œæ¥­ã‚’ç°¡ç´ åŒ–ã™ã‚‹ãŸã‚ã® Terraform Wrapper ã¨ã—ã¦çŸ¥ã‚‰ã‚Œã‚‹ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ã®ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚Terragrunt ã¯ Terraform ãŒæä¾›ã™ã‚‹æ©Ÿèƒ½ã‚’æ‹¡å¼µã—ã€ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚³ãƒ¼ãƒ‰å†åˆ©ç”¨ã€æŸ”è»Ÿãªæ§‹æˆã€å†åˆ©ç”¨æ€§ã®å‘ä¸Šã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚ç‰¹ã«ã€Terraform ã‚’ä½¿ç”¨ã—ã¦è¤‡æ•°ã®ç’°å¢ƒã‚„ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ç®¡ç†ã™ã‚‹éš›ã« Terragrunt ã¯éå¸¸ã«ä¾¿åˆ©ã§ã™ã€‚\nã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« $ brew install tfenv # Installs Terraform (version specified in .terraform-version) $ brew install tgenv # Installs Terragrunt (version specified in .terragrunt-version) ###ã€€ãƒ•ã‚©ãƒ«ãƒ€æ§‹æˆ\nã“ã®ãƒ•ã‚©ãƒ«ãƒ€æ§‹æˆã¯ã€ä»–ã®è¨˜äº‹ã‚’å‚è€ƒã«ä½œæˆã•ã‚Œã¾ã—ãŸã€‚ã“ã®æ§‹é€ ã®åˆ©ç‚¹ã¯ã€å„ç’°å¢ƒã”ã¨ã«ç•°ãªã‚‹å¤‰æ•°ã‚’æŒ‡å®šã§ãã‚‹ãŸã‚ã€ã‚³ãƒ¼ãƒ‰ã®å†åˆ©ç”¨æ€§ãŒå‘ä¸Šã™ã‚‹ã“ã¨ã§ã™ã€‚\n$ tree . . â”œâ”€â”€ README.md â”œâ”€â”€ docs â”‚ â””â”€â”€ graph-dependencies.png â”œâ”€â”€ envs â”‚ â”œâ”€â”€ prod â”‚ â”‚ â”œâ”€â”€ ResourceGroupA â”‚ â”‚ â”‚ â””â”€â”€ terragrunt.hcl â”‚ â”‚ â”œâ”€â”€ ResourceGroupB â”‚ â”‚ â”‚ â””â”€â”€ terragrunt.hcl â”‚ â”‚ â””â”€â”€ env.hcl â”‚ â””â”€â”€ terragrunt.hcl â””â”€â”€ modules â”œâ”€â”€ ResourceGroupA â”‚ â””â”€â”€ xx.tf â””â”€â”€ ResourceGroupB â””â”€â”€ xx.tf å…±é€šãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆenvs/terragrunt.hclï¼‰ ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯ã€ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã¨ã—ã¦ AWS S3 ãƒã‚±ãƒƒãƒˆã«*.tfstate ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã™ã‚‹ãŸã‚ã®è¨­å®šãŒå«ã¾ã‚Œã¦ãŠã‚Šã€å„ç’°å¢ƒã«ç‹¬è‡ªã®*.tfstate ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ S3 ãƒã‚±ãƒƒãƒˆå†…ã«ä¿å­˜ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ã¾ãŸã€AWS ãƒªã‚½ãƒ¼ã‚¹ã‚’ä½œæˆã™ã‚‹ãŸã‚ã« Terraform ãŒä½¿ç”¨ã™ã‚‹ãƒ—ãƒ­ãƒã‚¤ãƒ€ã®å®šç¾©ã‚‚å«ã¾ã‚Œã¦ã„ã¾ã™ã€‚è¨­å®šã§ã¯ã€å„ AWS ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã”ã¨ã«ç•°ãªã‚‹ãƒ—ãƒ­ãƒã‚¤ãƒ€è¨­å®šãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã™ã€‚\n*.tfstate ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãƒªã‚½ãƒ¼ã‚¹ã®çŠ¶æ…‹ã‚’ç®¡ç†ã™ã‚‹ã“ã¨ã§ã€è¤‡æ•°ã®äººãŒãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«å–ã‚Šçµ„ã‚“ã§ã„ã¦ã‚‚ç«¶åˆã‚’å›é¿ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\n# Configuration for storing *.tfstate files for each environment remote_state { backend = \u0026#34;s3\u0026#34; config = { bucket = \u0026#34;tfstate-xxxxxxxxxxxxxx\u0026#34; # Stored in `stg/modA.tfstate` key = \u0026#34;${path_relative_to_include()}.tfstate\u0026#34; region = \u0026#34;ap-northeast-1\u0026#34; encrypt = true } generate = { path = \u0026#34;backend.tf\u0026#34; if_exists = \u0026#34;overwrite\u0026#34; } } generate \u0026#34;provider\u0026#34; { path = \u0026#34;provider.tf\u0026#34; if_exists = \u0026#34;overwrite_terragrunt\u0026#34; contents = \u0026lt;\u0026lt;EOF terraform { required_version = \u0026#34;\u0026gt;= 1.3.7\u0026#34; required_providers { aws = { source = \u0026#34;hashicorp/aws\u0026#34; version = \u0026#34;~\u0026gt; 4.53.0\u0026#34; } } } # Tokyo region provider \u0026#34;aws\u0026#34; { region = \u0026#34;ap-northeast-1\u0026#34; alias = \u0026#34;tokyo\u0026#34; } # Virginia region provider \u0026#34;aws\u0026#34; { region = \u0026#34;us-east-1\u0026#34; alias = \u0026#34;virginia\u0026#34; } # ... Other regions EOF } ç’°å¢ƒå›ºæœ‰ã®ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆenvs/prod/env.hclï¼‰ ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€Terragrunt ã®ç’°å¢ƒå›ºæœ‰ã®ãƒ•ã‚¡ã‚¤ãƒ«ã§ã‚ã‚Šã€prod ç’°å¢ƒã®è¨­å®šãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚ã“ã‚Œã‚‰ã®å¤‰æ•°ã¯ã€ä»–ã® Terragrunt ãƒ•ã‚¡ã‚¤ãƒ«ã§ä½¿ç”¨ã•ã‚Œã€ç’°å¢ƒå›ºæœ‰ã®è¨­å®šã‚’å®šç¾©ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚å…·ä½“çš„ã«ã¯ã€envs/prod/ResourceGroupA ã® hcl ãƒ•ã‚¡ã‚¤ãƒ«ã§å‘¼ã³å‡ºã•ã‚Œã€Terraform ã‚³ãƒ¼ãƒ‰ã® module/ResourceGroupA ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã—ã¦æ¸¡ã•ã‚Œã¾ã™ã€‚\nlocals { ENV = \u0026#34;prod\u0026#34; PROJECT_NAME = \u0026#34;test\u0026#34; ACCOUNT_ID = \u0026#34;123456789\u0026#34; VPC_CIDE = \u0026#34;10.0.0.0/24\u0026#34; } å„ãƒªã‚½ãƒ¼ã‚¹ã‚°ãƒ«ãƒ¼ãƒ—ã®ãŸã‚ã® HCL ãƒ•ã‚¡ã‚¤ãƒ« ã€ŒResourceGroupAã€ã¨ã€ŒResourceGroupBã€ã® HCL ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¾‹ã‚’ç¤ºã—ã¾ã—ã‚‡ã†ã€‚\næœ€åˆã¯ä¾å­˜é–¢ä¿‚ãŒãªã„ã¨ä»®å®šã—ã€A ã¨ã„ã†ã‚¯ãƒªãƒ¼ãƒ³ãªã‚¹ãƒ¬ãƒ¼ãƒˆã®ã‚·ãƒŠãƒªã‚ªã‚’è€ƒãˆã¾ã™ã€‚B ã¯ A ã«ä¾å­˜ã™ã‚‹ãƒªã‚½ãƒ¼ã‚¹ã‚°ãƒ«ãƒ¼ãƒ—ã¨ã—ã¾ã™ã€‚\nã€ŒResourceGroupAã€ã® HCL ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ vim envs/prod/ResourceGroupA/terragrunt.hcl env.hcl ã‹ã‚‰å¤‰æ•°ã‚’å—ã‘å–ã‚Šã€ãã‚Œã‚‰ã‚’ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«å€¤ã¨ã—ã¦æ¸¡ã—ã¾ã™ã€‚ locals { ENV = read_terragrunt_config(find_in_parent_folders(\u0026#34;env.hcl\u0026#34;)) } # Include definition of all environments (envs/terragrunt.hcl) include { path = find_in_parent_folders() } terraform { # Reference the module source = \u0026#34;../../../modules//ResourceGroupA\u0026#34; } # Specify the input values for the module inputs = { ENV = local.ENV.locals.ENV PROJECT_NAME = local.ENV.locals.PROJECT_NAME ACCOUNT_ID = local.ENV.locals.ACCOUNT_ID } ã€ŒResourceGroupBã€ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆï¼š vim envs/prod/ResourceGroupB/terragrunt.hcl env.hcl ã‹ã‚‰å¤‰æ•°ã‚’å–å¾—ã—ã€ãã‚Œã‚‰ã‚’ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã«æ¸¡ã—ã¾ã™ã€‚ ã“ã®ä¾‹ã§ã¯ã€ResourceGroupA ã§ä½œæˆã—ãŸ VPC ã® ID ã‚’ ResourceGroupB ã«æ¸¡ã™ã“ã¨ã‚’æƒ³å®šã—ã¦ã„ã¾ã™ã€‚ locals { ENV = read_terragrunt_config(find_in_parent_folders(\u0026#34;env.hcl\u0026#34;)) } # Include definition of all environments (envs/terragrunt.hcl) include { path = find_in_parent_folders() } terraform { # Reference the module source = \u0026#34;../../../modules//ResourceGroupB\u0026#34; } # Specify the input values for the module inputs = { ENV = local.ENV.locals.ENV PROJECT_NAME = local.ENV.locals.PROJECT_NAME ACCOUNT_ID = local.ENV.locals.ACCOUNT_ID VPC_ID = local.ENV.locals.VPC_ID } ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã® tf ãƒ•ã‚¡ã‚¤ãƒ« ä¸€èˆ¬çš„ã«ã¯ã€é€šå¸¸ã©ãŠã‚Š Terraform ã®ã‚³ãƒ¼ãƒ‰ã‚’è¨˜è¿°ã§ãã¾ã™ã€‚ ä»–ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å—ã‘å–ã‚ŠãŸã„å ´åˆï¼ˆä¾å­˜é–¢ä¿‚ãŒã‚ã‚‹å ´åˆã‚„ env.hcl ã‹ã‚‰ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ¸¡ã™å ´åˆï¼‰ã€å¤‰æ•°ãƒ–ãƒ­ãƒƒã‚¯ã§ç©ºã®å¤‰æ•°ã‚’å®šç¾©ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ä¸Šè¨˜ã§è¨€åŠã—ãŸ ResourceGroupB ã®ä¾‹ã§ã¯ã€æ¬¡ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ã€‚ variable \u0026#34;ENV\u0026#34; { description = \u0026#34;Environment\u0026#34; type = string } variable \u0026#34;PROJECT_NAME\u0026#34; { description = \u0026#34;Project Name\u0026#34; type = string } variable \u0026#34;vpc_id\u0026#34; { description = \u0026#34;The ID of the VPC\u0026#34; type = string } 1 ã¤ã®ãƒªã‚½ãƒ¼ã‚¹ã‚°ãƒ«ãƒ¼ãƒ—ã‹ã‚‰åˆ¥ã®ãƒªã‚½ãƒ¼ã‚¹ã‚°ãƒ«ãƒ¼ãƒ—ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ¸¡ã™å ´åˆã¯ã€ãã‚Œã‚‰ã‚’å‡ºåŠ›ã¨ã—ã¦å®šç¾©ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ä¾‹ãˆã°ã€Resource Group A ã®å ´åˆã€ä»¥ä¸‹ã®ã‚ˆã†ã«å®šç¾©ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼š output \u0026#34;vpc_id\u0026#34; { value = aws_vpc.main.id } Deployment Terragrunt Commands Formatting cd envs/prod terragrunt run-all hclfmt terragrunt run-all fmt validate cd envs/prod terragrunt validate-all plan cd envs/prod terragrunt run-all plan apply cd envs/prod terragrunt run-all apply Dependency Graph tips Installing dot command on M1 Mac: Graphviz is a graph visualization tool that includes the dot command. You can install Graphviz by running the following command in the terminal: brew install graphviz Verify if the dot command is installed: dot -V cd envs/terragrunt-prod terragrunt graph-dependencies | dot -Tpng \u0026gt; graph-dependencies.png Deployment from git GithubAction name: Terragrunt Actions on: push: branches: - master env: TERRAGRUNT_CACHE_DIR: ${{ github.workspace }}/tool jobs: build: runs-on: ubuntu-latest env: TARGET_ENV: \u0026#39;\u0026#39; steps: - name: Set Production run: | mkdir -p ${GITHUB_WORKSPACE}/deploy echo \u0026#39;export TARGET_ENV=\u0026#34;prod\u0026#34;\u0026#39; \u0026gt;\u0026gt; ${GITHUB_WORKSPACE}/deploy/.env if: github.ref == \u0026#39;refs/heads/master\u0026#39; env: GITHUB_WORKSPACE: ${{ github.workspace }} - name: Set Staging run: | mkdir -p ${GITHUB_WORKSPACE}/deploy echo \u0026#39;export TARGET_ENV=\u0026#34;stg\u0026#34;\u0026#39; \u0026gt;\u0026gt; ${GITHUB_WORKSPACE}/deploy/.env if: github.ref == \u0026#39;refs/heads/staging\u0026#39; env: GITHUB_WORKSPACE: ${{ github.workspace }} - name: Terragrunt Plan env: TERRAGRUNT_DOWNLOAD: \u0026#34;https://github.com/gruntwork-io/terragrunt/releases/download/v0.34.0/terragrunt_linux_amd64\u0026#34; run: | source ${GITHUB_WORKSPACE}/deploy/.env sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install -y curl unzip git curl -Lo /tmp/terragrunt.zip ${TERRAGRUNT_DOWNLOAD} sudo unzip -d /usr/local/bin /tmp/terragrunt.zip cd ${GITHUB_WORKSPACE}/envs/${TARGET_ENV} terragrunt run-all plan if: github.ref == \u0026#39;refs/heads/master\u0026#39; || github.ref == \u0026#39;refs/heads/staging\u0026#39; env: GITHUB_WORKSPACE: ${{ github.workspace }} TERRAGRUNT_CACHE_DIR: ${{ env.TERRAGRUNT_CACHE_DIR }} - name: Terragrunt Apply if: github.ref == \u0026#39;refs/heads/master\u0026#39; env: TERRAGRUNT_DOWNLOAD: \u0026#34;https://github.com/gruntwork-io/terragrunt/releases/download/v0.34.0/terragrunt_linux_amd64\u0026#34; run: | source ${GITHUB_WORKSPACE}/deploy/.env sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install -y curl unzip git curl -Lo /tmp/terragrunt.zip ${TERRAGRUNT_DOWNLOAD} sudo unzip -d /usr/local/bin /tmp/terragrunt.zip cd ${GITHUB_WORKSPACE}/envs/${TARGET_ENV} terragrunt run-all apply --terragrunt-non-interactive env: GITHUB_WORKSPACE: ${{ github.workspace }} TERRAGRUNT_CACHE_DIR: ${{ env.TERRAGRUNT_CACHE_DIR }} Bitbucket-Pipelines image: hashicorp/terraform:1.3.7 definitions: caches: terragrunt: ${BITBUCKET_CLONE_DIR}/tool steps: - step: \u0026amp;set-production name: Set Production script: - mkdir -p ${BITBUCKET_CLONE_DIR}/deploy - echo \u0026#39;export TARGET_ENV=\u0026#34;prod\u0026#34;\u0026#39; \u0026gt;\u0026gt; ${BITBUCKET_CLONE_DIR}/deploy/.env artifacts: - deploy/** - step: \u0026amp;set-staging name: Set Staging script: - mkdir -p ${BITBUCKET_CLONE_DIR}/deploy - echo \u0026#39;export TARGET_ENV=\u0026#34;stg\u0026#34;\u0026#39; \u0026gt;\u0026gt; ${BITBUCKET_CLONE_DIR}/deploy/.env artifacts: - deploy/** - step: \u0026amp;terragrunt-plan name: terragrunt Plan caches: - terragrunt script: - source ${BITBUCKET_CLONE_DIR}/deploy/.env - apk update \u0026amp;\u0026amp; apk add bash curl groff jq less unzip git - if [ ! -d ${BITBUCKET_CLONE_DIR}/tool/tfenv ]; then git clone https://github.com/tfutils/tfenv.git ${BITBUCKET_CLONE_DIR}/tool/tfenv; fi - if [ ! -d ${BITBUCKET_CLONE_DIR}/tool/tgenv ]; then git clone https://github.com/cunymatthieu/tgenv.git ${BITBUCKET_CLONE_DIR}/tool/tgenv; fi - export PATH=${BITBUCKET_CLONE_DIR}/tool/tfenv/bin:$PATH - export PATH=${BITBUCKET_CLONE_DIR}/tool/tgenv/bin:$PATH - cd ${BITBUCKET_CLONE_DIR}/envs/${TARGET_ENV} - tfenv install \u0026amp;\u0026amp; tgenv install - terragrunt run-all plan - step: \u0026amp;terragrunt-apply name: terragrunt Apply trigger: manual caches: - terragrunt script: - source ${BITBUCKET_CLONE_DIR}/deploy/.env - apk update \u0026amp;\u0026amp; apk add bash curl groff jq less unzip git - if [ ! -d ${BITBUCKET_CLONE_DIR}/tool/tfenv ]; then git clone https://github.com/tfutils/tfenv.git ${BITBUCKET_CLONE_DIR}/tool/tfenv; fi - if [ ! -d ${BITBUCKET_CLONE_DIR}/tool/tgenv ]; then git clone https://github.com/cunymatthieu/tgenv.git ${BITBUCKET_CLONE_DIR}/tool/tgenv; fi - export PATH=${BITBUCKET_CLONE_DIR}/tool/tfenv/bin:$PATH - export PATH=${BITBUCKET_CLONE_DIR}/tool/tgenv/bin:$PATH - cd ${BITBUCKET_CLONE_DIR}/envs/${TARGET_ENV} - tfenv install \u0026amp;\u0026amp; tgenv install - terragrunt run-all apply --terragrunt-non-interactive pipelines: default: - step: *set-production - step: *terragrunt-plan branches: master: - step: *set-production - step: *terragrunt-plan - step: \u0026lt;\u0026lt;: *terragrunt-apply deployment: production ","permalink":"https://h-neco.github.io/blog/cicd-terragrunt-1/","tags":["DevOps"],"title":"Terraformã®Wrapperãƒ„ãƒ¼ãƒ«ã€Terragruntå°å…¥ã®æ¤œè¨¼ã‚’è¡Œã„ã¾ã—ãŸã€‚"},{"categories":null,"contents":"Intro AmazonLinux2 ã‚’ä½¿ç”¨ã—ã¦ NAT ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’è¨­å®šã—ã¾ã—ãŸã€‚æ§‹æˆãƒ—ãƒ­ã‚»ã‚¹ã« Packer ã¨ Ansible ã‚’ä½¿ç”¨ã—ã¾ã—ãŸã€‚\nAmazonLinux2 ã‚’ä½¿ç”¨ã—ã¦ NAT ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’è¨­å®šã—ã¾ã™ã€‚ Amazonlinux2 ãŒé¸æŠã™ã‚‹ç†ç”± Lambda ã¯å¤–éƒ¨ã‹ã‚‰é–‹å§‹ã•ã‚Œã‚‹ç€ä¿¡æ¥ç¶šã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ãªã„ãŸã‚ã€ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ¼ãƒ‰ã§ FTP ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã›ã‚“ã€‚ ECS ã¯ã€ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆ IP ã‚¢ãƒ‰ãƒ¬ã‚¹ã®é™çš„å‰²ã‚Šå½“ã¦ã‚’è¨±å¯ã—ã¦ã„ã¾ã›ã‚“ã€‚ Gateway ã‚¿ã‚¤ãƒ—ã§ã‚ã‚‹ãŸã‚ã€NAT ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆã‚²ãƒ¼ãƒˆã‚¦ã‚§ã‚¤ã¨çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§é™çš„å‰²ã‚Šå½“ã¦ã‚’å®Ÿç¾ã™ã‚‹ã“ã¨ã¯å¯èƒ½ã§ã™ãŒã€å¤–éƒ¨ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã®ç€ä¿¡æ¥ç¶šã‚’å—ã‘å…¥ã‚Œã‚‹ã“ã¨ã¯ã§ãã¾ã›ã‚“ã€‚ æŠ€è¡“è¦ç´  Packer Ansible iptables CENTOS7ï¼ˆAmazonLinux2ï¼‰ã§ã¯ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ•ã‚¡ã‚¤ã‚¢ã‚¦ã‚©ãƒ¼ãƒ«ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã¯ãƒ•ã‚¡ã‚¤ã‚¢ã‚¦ã‚©ãƒ¼ãƒ«ã§ã™ã€‚ãŸã ã—ã€IPTables ã‚’ç´¹ä»‹ã—ã¦ã€NAT ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã—ã¾ã™ã€‚ ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€  $ tree . . â”œâ”€â”€ ansible.cfg â”œâ”€â”€ bin â”‚Â â””â”€â”€ init.sh â”œâ”€â”€ inventory â”‚Â â””â”€â”€ hosts â”œâ”€â”€ packer-template â”‚Â â””â”€â”€ nat_instance.json â”œâ”€â”€ playbook â”‚Â â””â”€â”€ setup.yml â””â”€â”€ roles â””â”€â”€ iptable â””â”€â”€ tasks â”œâ”€â”€ main.yml â””â”€â”€ templates â”œâ”€â”€ iptables-config.j2 â”œâ”€â”€ nat_cidr.j2 â””â”€â”€ sysctl.conf Packer ã¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å®Ÿè¡Œ Execution Command packer build packer-template/nat_instance.json . â””â”€â”€ packer-template â””â”€â”€ nat_instance.json { \u0026#34;variables\u0026#34;: { \u0026#34;aws_access_key\u0026#34;: \u0026#34;{{env `AWS_ACCESS_KEY`}}\u0026#34;, \u0026#34;aws_secret_key\u0026#34;: \u0026#34;{{env `AWS_SECRET_KEY`}}\u0026#34; }, \u0026#34;builders\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;amazon-ebs\u0026#34;, \u0026#34;access_key\u0026#34;: \u0026#34;{{user `aws_access_key`}}\u0026#34;, \u0026#34;secret_key\u0026#34;: \u0026#34;{{user `aws_secret_key`}}\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;ap-northeast-1\u0026#34;, \u0026#34;ami_regions\u0026#34;: [ \u0026#34;ap-northeast-1\u0026#34; ], \u0026#34;associate_public_ip_address\u0026#34;: true, \u0026#34;source_ami\u0026#34;: \u0026#34;ami-0a3d21ec6281df8cb\u0026#34;, \u0026#34;instance_type\u0026#34;: \u0026#34;t3.micro\u0026#34;, \u0026#34;ssh_username\u0026#34;: \u0026#34;ec2-user\u0026#34;, \u0026#34;ami_name\u0026#34;: \u0026#34;nat-{{timestamp}}\u0026#34;, \u0026#34;tags\u0026#34;: { \u0026#34;Name\u0026#34;: \u0026#34;nat-instance\u0026#34; }, \u0026#34;ena_support\u0026#34;: true, \u0026#34;enable_t2_unlimited\u0026#34;: false } ], \u0026#34;provisioners\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;shell\u0026#34;, \u0026#34;script\u0026#34;: \u0026#34;./bin/init.sh\u0026#34;, \u0026#34;pause_before\u0026#34;: \u0026#34;60s\u0026#34; }, { \u0026#34;type\u0026#34;: \u0026#34;ansible-local\u0026#34;, \u0026#34;inventory_file\u0026#34;: \u0026#34;inventory/hosts\u0026#34;, \u0026#34;playbook_file\u0026#34;: \u0026#34;playbook/setup.yml\u0026#34;, \u0026#34;role_paths\u0026#34;: [ \u0026#34;roles/iptable\u0026#34; ], \u0026#34;staging_directory\u0026#34;: \u0026#34;/tmp/ansible-local\u0026#34;, \u0026#34;extra_arguments\u0026#34;: [\u0026#34;-vv\u0026#34;] }] } Ansible ã®æº–å‚™ ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ . â”œâ”€â”€ ansible.cfg â”œâ”€â”€ bin â”‚Â â””â”€â”€ init.sh â””â”€â”€ inventory â””â”€â”€ hosts Install ansible Ansible ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¯ã€ ã€‚/bin/init.shã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ã§å®Ÿè¡Œã§ãã¾ã™\n#!/bin/bash sudo yum -y update # ansible install amazon-linux-extras install epel amazon-linux-extras enable ansible2 amazon-linux-extras install ansible2 ã‚¤ãƒ³ãƒ™ãƒ³ãƒˆãƒªãƒ•ã‚¡ã‚¤ãƒ«ã®æ§‹æˆ inventory/hosts ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ç½®ã—ã¾ã™ã€‚\nè¨­å®šã—ãŸã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰ãƒ­ãƒ¼ã‚«ãƒ«ã§ Ansible ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ã—ã¦ã€Œãƒ­ãƒ¼ã‚«ãƒ«ã€ã‚’æŒ‡å®šã—ã¾ã™ã€‚\n[default] 127.0.0.1 æ§‹æˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ç½®ã—ã¾ã™ ansible.cfgãƒ•ã‚¡ã‚¤ãƒ«ã‚’é…ç½®ã—ã¾ã™\nã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€Ansible ã®å®Ÿè¡Œã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚ä»¥ä¸‹ã¯ã‚µãƒ³ãƒ—ãƒ«æ§‹æˆã§ã™ã€‚\n[defaults] # Specify the Python interpreter interpreter_python=/usr/bin/python3 # Location of the hosts file inventory = inventroy/hosts # Whether to validate host keys when connecting host_key_checking = True # Number of parallel processes to use for remote connections forks=5 # Path to the log file log_path=~/logs/ansible/ansible.log # Color settings nocolor=0 scp_if_ssh=True Ansible Playbook ã‚’ä½œæˆã—ã¾ã™ file Structure . â”œâ”€â”€ playbook â”‚Â â””â”€â”€ setup.yml â””â”€â”€ roles â””â”€â”€ iptable â””â”€â”€ tasks â”œâ”€â”€ main.yml â””â”€â”€ templates â”œâ”€â”€ iptables-config.j2 â”œâ”€â”€ nat_cidr.j2 â””â”€â”€ sysctl.conf Packer ã«ã‚ˆã£ã¦å‘¼ã³å‡ºã•ã‚Œã‚‹ Playbook/setup.yml ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã™ã€‚ iptables ã®ãƒ­ãƒ¼ãƒ«ã‚’å‘¼ã³å‡ºã—ã€ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°å¾Œã«å‡ºå£æ™‚ã«ã‚½ãƒ¼ã‚¹ã‚¢ãƒ‰ãƒ¬ã‚¹/ãƒãƒ¼ãƒˆå¤‰æ›ã‚’å®Ÿè¡Œã™ã‚‹ãƒã‚§ãƒ¼ãƒ³ã‚’æ¸¡ã—ã¾ã™ã€‚\n--- - hosts: all become: yes become_user: root remote_user: ec2-user roles: - role: iptable vars: nat_cidr: 10.0.0.1/24 ã¾ãŸã€playbook ã‹ã‚‰å‘¼ã³å‡ºã•ã‚Œã‚‹ iptables ãƒ­ãƒ¼ãƒ«ã® main.yml ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚æ›¸ãã¾ã™ã€‚ä¸»ãªæ§‹æˆã¯ã€iptables ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨å¿…è¦ãªè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®æ§‹æˆã§ã™ã€‚\nroles/iptable/tasks/main.yml --- - name: Install iptables-service yum: name=iptables-services state=latest - name: Enable port forwarding template: src=\u0026#34;sysctl.conf\u0026#34; dest=\u0026#34;/etc/sysctl.conf\u0026#34; owner=root group=root mode=0644 # IP tables - name: Make iptables file template: src=\u0026#34;{{ item }}.j2\u0026#34; dest=\u0026#34;/etc/sysconfig/{{ item }}\u0026#34; owner=root group=root mode=0600 with_items: - \u0026#34;nat_cidr\u0026#34; # IP tables config - name: Make iptables-config file template: src=\u0026#34;iptables-config.j2\u0026#34; dest=\u0026#34;/etc/sysconfig/iptables-config-nat\u0026#34; owner=root group=root mode=0600 - name: Install ftp command yum: name=ftp state=latest - name: Install tcpdump command yum: name=tcpdump state=latest - name: Install lftp command yum: name=lftp state=latest ä¸Šè¨˜ã§ä½¿ç”¨ã—ãŸãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›¸ãè¾¼ã‚“ã§ã„ãã¾ã™ã€‚ roles/iptable/tasks/templates/iptables-config.j2 roles/iptable/tasks/templates/sysctl.conf roles/iptable/tasks/templates/nat_cidr.j2 roles/iptable/tasks/templates/iptables-config.j2\nIPTABLES_MODULES=\u0026#34;nf_conntrack_ftp nf_nat_ftp\u0026#34; IPTABLES_MODULES_UNLOAD=\u0026#34;yes\u0026#34; IPTABLES_SAVE_ON_STOP=\u0026#34;no\u0026#34; IPTABLES_SAVE_ON_RESTART=\u0026#34;no\u0026#34; IPTABLES_SAVE_COUNTER=\u0026#34;no\u0026#34; IPTABLES_STATUS_NUMERIC=\u0026#34;yes\u0026#34; IPTABLES_STATUS_VERBOSE=\u0026#34;no\u0026#34; IPTABLES_STATUS_LINENUMBERS=\u0026#34;yes\u0026#34; roles/iptable/tasks/templates/sysctl.conf\nIPv4 ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã¨å‘¼ã°ã‚Œã‚‹æ©Ÿèƒ½ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã«ã¯ã€ã€Œ/proc/sys/net/ipv4/ip_forwardã€ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ã€Œ1ã€ã«è¨­å®šã™ã‚‹ã€‚\nnet.ipv4.ip_forward=1 roles/iptable/tasks/templates/nat_cidr.j2\n*filter :INPUT ACCEPT [0:0] :FORWARD ACCEPT [0:0] :OUTPUT ACCEPT [0:0] COMMIT *nat :POSTROUTING ACCEPT [0:0] -A POSTROUTING -s {{ nat_cidr }} -j MASQUERADE COMMIT *raw :PREROUTING ACCEPT [0:0] -A PREROUTING -p tcp --dport 21 -j CT --helper ftp COMMIT EC2 ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¨­å®šã‚’æ§‹æˆã™ã‚‹ã«ã¯ ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹æ§‹æˆã§ã€NAT ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã® Elastic Network Interface (ENI)ã®å®›å…ˆãƒã‚§ãƒƒã‚¯ã‚’ç„¡åŠ¹ã«ã—ã¾ã™ã€‚\naws ec2 modify-instance-attribute \\ --no-source-dest-check \\ --instance-id ${INSTANCE_ID} ã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã—ã¦ iptables ã‚’èµ·å‹•ã™ã‚‹ã«ã¯ Ansible ã‚’ä½¿ã£ã¦è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‡ãƒ—ãƒ­ã‚¤ã—ã€iptables ã‚’å†èµ·å‹•ã™ã‚‹ã«ã¯\n# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’Ansibleã§é…å¸ƒã•ã‚Œã¦ã„ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã§ä¸Šæ›¸ãã™ã‚‹ sudo cp /etc/sysconfig/iptables-config-nat /etc/sysconfig/iptables # è¨­å®šã®æ°¸ç¶šåŒ– sudo service iptables save # ã‚µãƒ¼ãƒ“ã‚¹ã‚’å†èµ·å‹•ã™ã‚‹ sudo systemctl restart iptables ","permalink":"https://h-neco.github.io/blog/aws-ec2-nat-instance/","tags":["AWS"],"title":"Packerã¨Ansibleã‚’ä½¿ç”¨ã—ã¦Amazon Linux 2ã«NATã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆã—ã¾ã™ã€‚"},{"categories":null,"contents":"èƒŒæ™¯ NFS ã‹ã‚‰ s3 ã¸ãƒ‡ãƒ¼ã‚¿ã‚’ç§»è¡Œã—ã¦ WEB ãƒ›ã‚¹ãƒ†ã‚£ãƒ³ã‚°ã™ã‚‹ã‚ˆã†ã«åŸºç›¤ç§»è¡Œã‚’è¡Œã£ãŸéš›ã€404 ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆãŒå¤šæ•°ç™ºç”Ÿã—ã¦ã„ãŸã€‚ ã¾ãŸã€s3 ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆåãƒ»ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹åã«ã¯ç¦å‰‡æ–‡å­—ã¨ã„ã†ã‚‚ã®ãŒå­˜åœ¨ã™ã‚‹ã†ã‚‰ã—ã„ã€‚ ä½•ãŒå¯¾è±¡ãªã®ã‹åˆ¤æ–­ã™ã‚‹ãŸã‚ã«ã€ãƒ–ãƒ©ã‚¦ã‚¶ã®ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ãƒ­ã‚°ã‚’å–å¾—ã™ã‚‹å¿…è¦ãŒã‚ã£ãŸã€‚\nå‹•ä½œç’°å¢ƒ ç’°å¢ƒãƒ»ãƒ„ãƒ¼ãƒ«\n$ sw_vers ProductName: Mac OS X ProductVersion: 10.15.2 BuildVersion: 19C57 $ python3 -V Python 3.7.3z $ pip3 list | grep -e chrome -e selenium chromedriver-binary 83.0.4103.39.0 selenium 3.141.0 install æ‰‹é †\n$ sudo pip3 install selenium $ sudo pip3 install chromedriver-binary==83.0.4103.39.0 æŠ€è¡“è¦ç´  selenium web driver python ec2 ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ ./log/ (ãƒ­ã‚°å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª) ./config.ini (è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«) ./grep.py (å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«) ./url.txt (æ¤œç´¢å¯¾è±¡ã®URLãƒªã‚¹ãƒˆ) å®Ÿè¡Œæº–å‚™ ã‚¯ãƒ­ãƒ¼ãƒªãƒ³ã‚°å¯¾è±¡ã® URL ã‚’è¨˜è¼‰ã™ã‚‹ $ vi url.txt http://user:password@google.com/ http://www.google.com/ ... config ãƒ•ã‚¡ã‚¤ãƒ«ã®é…ç½® $ vi config.ini [INTERVAL] TIME_SEC = 5 [URL] FILE = url.txt [RESPONSE_CODE] OK = 200 [LOG] DIR = ./log/ TARGET = browser LEVEL = SEVERE TEXT_START = START TEXT_DONE = DONE å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ã®é…ç½® #!/usr/bin/env python3 # -*- coding: utf-8 -*- # selenium from selenium import webdriver from selenium.webdriver.common.desired_capabilities import DesiredCapabilities from selenium.webdriver.chrome.options import Options import chromedriver_binary # other modules import re import os import signal import datetime import logging import time import configparser # iniãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ conf = configparser.ConfigParser() conf.read(\u0026#39;config.ini\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) # ãƒ­ã‚°è¨­å®š logging.basicConfig( filename= conf[\u0026#39;LOG\u0026#39;].get(\u0026#39;DIR\u0026#39;) + datetime.datetime.now().strftime(\u0026#39;%Y%m%d_%H%M%S\u0026#39;) + \u0026#39;.log\u0026#39;, level=logging.INFO, format=\u0026#39;%(asctime)s %(levelname)s %(message)s\u0026#39; ) # chrome webdriver ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã®æŒ‡å®š â€»ã‚ªãƒ—ã‚·ãƒ§ãƒ³è¨­å®šã®å½±éŸ¿ã‚’å—ã‘ã‚‹ caps = DesiredCapabilities.CHROME caps[\u0026#34;goog:loggingPrefs\u0026#34;] = {conf[\u0026#39;LOG\u0026#39;].get(\u0026#39;TARGET\u0026#39;):conf[\u0026#39;LOG\u0026#39;].get(\u0026#39;LEVEL\u0026#39;)} # chrome ã‚ªãƒ—ã‚·ãƒ§ãƒ³è¨­å®š options = Options() options.add_argument(\u0026#39;--headless\u0026#39;) # ãƒ–ãƒ©ã‚¦ã‚¶ãƒ¼ã®UIãªã—ã«ã™ã‚‹ options.add_argument(\u0026#39;--ignore-certificate-errors\u0026#39;) # SSLè¨¼æ˜æ›¸å¤±åŠ¹ã‚µã‚¤ãƒˆå¯¾ç­– # ä»–ã«ã‚‚é©å®œã‚ªãƒ—ã‚·ãƒ§ãƒ³è¿½åŠ ã§ãã‚‹ã€‚mobileUIã«ã™ã‚‹ãªã©ã€‚ def main(): try: logging.info(conf[\u0026#39;LOG\u0026#39;].get(\u0026#39;TEXT_START\u0026#39;)) # Webdriver browser = webdriver.Chrome(desired_capabilities=caps,options=options) f = open(conf[\u0026#39;URL\u0026#39;].get(\u0026#39;FILE\u0026#39;)) urlList = f.read() f.close() urls = urlList.split(\u0026#39;\\n\u0026#39;) count = 1 for url in urls: if len(url) == 0: logging.info(conf[\u0026#39;LOG\u0026#39;].get(\u0026#39;TEXT_DONE\u0026#39;)) break else: # URLã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒã‚§ãƒƒã‚¯ status = requests.get(str(url)) # å¯¾è±¡URLåŠã³ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã®ãƒ­ã‚°å‡ºåŠ› target_url_log = str(count) + \u0026#34;:\u0026#34; + str(status) + \u0026#34;:\u0026#34; + str(url) print(target_url_log) # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰ãŒ200ã®å ´åˆã¯INFOã€ãã‚Œä»¥å¤–ã¯WARNINGã§ãƒ­ã‚°å‡ºåŠ› logging.info(target_url_log) if status.status_code == int(conf[\u0026#39;RESPONSE_CODE\u0026#39;].get(\u0026#39;OK\u0026#39;)) else logging.warning(target_url_log) if status.status_code == int(conf[\u0026#39;RESPONSE_CODE\u0026#39;].get(\u0026#39;OK\u0026#39;)): # å¯¾è±¡URLã‚’ãƒ–ãƒ©ã‚¦ã‚ºã—ã€æŒ‡å®šã—ãŸãƒ­ã‚°ã‚’å–å¾—ã™ã‚‹ browser.get(url) for _log in browser.get_log(conf[\u0026#39;LOG\u0026#39;].get(\u0026#39;TARGET\u0026#39;)): print(_log) logging.warning(_log) count += 1 # è² è·å¯¾ç­–ã®ãŸã‚sleepã‚’ã„ã‚Œã‚‹ time.sleep(int(conf[\u0026#39;INTERVAL\u0026#39;].get(\u0026#39;TIME_SEC\u0026#39;))) except Exception as e: print(e) logging.error(e) finally: # chromedriver ã®ãƒ—ãƒ­ã‚»ã‚¹ãŒæ®‹ã£ã¦ã—ã¾ã†ãŸã‚killã™ã‚‹ os.kill(browser.service.process.pid,signal.SIGTERM) if __name__ == \u0026#34;__main__\u0026#34;: main() å®Ÿè¡Œ $ python3 grep.py 2020-07-13 10:36:59,209 INFO START 2020-07-13 10:37:00,883 INFO 1:\u0026lt;Response [200]\u0026gt;:https://google.com/ 2020-07-13 10:37:10,228 WARNING 2:\u0026lt;Response [404]\u0026gt;:https://google.com/aaa 2020-07-13 10:37:17,021 INFO 3:\u0026lt;Response [200]\u0026gt;:http://www.google.com/googlegooglegooglegooglegoogle... 2020-07-13 10:37:22,576 WARNING {\u0026#39;level\u0026#39;: \u0026#39;SEVERE\u0026#39;, \u0026#39;message\u0026#39;: \u0026#39;xxx\u0026#39;, \u0026#39;source\u0026#39;: \u0026#39;network\u0026#39;, \u0026#39;timestamp\u0026#39;: 1594604239554} 2020-07-13 10:37:22,576 WARNING {\u0026#39;level\u0026#39;: \u0026#39;SEVERE\u0026#39;, \u0026#39;message\u0026#39;: \u0026#39;xxx\u0026#39;, \u0026#39;source\u0026#39;: \u0026#39;console-api\u0026#39;, \u0026#39;timestamp\u0026#39;: 1594604239823} 2020-07-13 10:37:22,576 WARNING {\u0026#39;level\u0026#39;: \u0026#39;SEVERE\u0026#39;, \u0026#39;message\u0026#39;: \u0026#39;xxx\u0026#39;, \u0026#39;source\u0026#39;: \u0026#39;console-api\u0026#39;, \u0026#39;timestamp\u0026#39;: 1594604241138} tips Chrome ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼ˆstable)ã¨ã€python ã® chromedriver-binary ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒã†ã¾ãåˆã‚ãªã„ã¨ã€ã†ã¾ãå‹•ã„ã¦ãã‚Œã¾ã›ã‚“ã€‚\nEC2(amazonlinux2)ã« chrome ã‚’å…¥ã‚Œã‚‹æ–¹æ³•\n## chrome install (yumã¯ä¾å­˜ã§è©°ã¾ã‚‹ã‹ã‚‰curl) $ curl https://intoli.com/install-google-chrome.sh | bash ## GConf2 ãƒªãƒã‚¸ãƒˆãƒªè¿½åŠ  (ChromeDeiverå‹•ã‹ã™ã®ã«å¿…è¦ã‚‰ã—ã„) $ sudo vim /etc/yum.repos.d/centos.repo [CentOS-base] name=CentOS-6 - Base mirrorlist=http://mirrorlist.centos.org/?release=6\u0026amp;arch=x86_64\u0026amp;repo=os gpgcheck=1 gpgkey=http://mirror.centos.org/centos/RPM-GPG-KEY-CentOS-6 #released updates [CentOS-updates] name=CentOS-6 - Updates mirrorlist=http://mirrorlist.centos.org/?release=6\u0026amp;arch=x86_64\u0026amp;repo=updates gpgcheck=1 gpgkey=http://mirror.centos.org/centos/RPM-GPG-KEY-CentOS-6 #additional packages that may be useful [CentOS-extras] name=CentOS-6 - Extras mirrorlist=http://mirrorlist.centos.org/?release=6\u0026amp;arch=x86_64\u0026amp;repo=extras gpgcheck=1 gpgkey=http://mirror.centos.org/centos/RPM-GPG-KEY-CentOS-6\u0026#34; GPG key ã‚¤ãƒ³ãƒãƒ¼ãƒˆ rpm --import http://mirror.centos.org/centos/RPM-GPG-KEY-CentOS-6 ## Google Noto Fontsã„ã‚Œã‚‹ï¼ˆã‚­ãƒ£ãƒ—ãƒãƒ£å–ã‚‹ã‚ã‘ã˜ã‚ƒãªã„ã‹ã‚‰å…¥ã‚Œãªãã¦ã‚‚ã„ã„ã®ã‹ã‚‚ï¼‰ $ Gconf2 install yum -y install GConf2 $ mkdir ~dl \u0026amp;\u0026amp; cd dl $ unzip Noto-hinted.zip $ mkdir -p /usr/share/fonts/opentype/noto $ cp *otf *ttf /usr/share/fonts/opentype/noto $ fc-cache -f -v ### python3ç³»ã„ã‚Œã‚‹ $ sudo yum install python3 $ sudo pip3 update $ sudo pip3 install --upgrade pip ### åˆ©ç”¨ã—ã¦ã„ã‚‹chromeã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¨åˆã‚ã›ã‚‹ # sudo pip3 install chromedriver-binary==84.0.4147.30 ","permalink":"https://h-neco.github.io/blog/browser-selenium/","tags":["Tools"],"title":"ãƒ–ãƒ©ã‚¦ã‚¶ã®ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ãƒ­ã‚°ã‚’Selenium(ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ–ãƒ©ã‚¦ã‚¶)ã§å–å¾—ã™ã‚‹"},{"categories":null,"contents":"tags tags Recent Posts Trivy ã‚’ç”¨ã„ãŸã‚³ãƒ³ãƒ†ãƒŠ Image,DockerFile ã¸ã®è„†å¼±æ€§è¨ºæ–­ 2024-03-21 multipass ã§ ãƒ­ãƒ¼ã‚«ãƒ« docker ç’°å¢ƒã®æ§‹ç¯‰ 2024-03-20 chatgpt+mermaid ã§ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å›³ã‚’ä½œæˆã™ã‚‹ 2024-02-21 CloudFrontFunction ã¨ LambdaEdge ã®é•ã„ 2023-07-21 Docker ã‹ã‚‰ Terraform ã‚’å®Ÿè¡Œã™ã‚‹ 2023-07-10 Codebuild æ§‹ç¯‰ã¨ Deploy ãƒ•ãƒ­ãƒ¼ã®æ•´å‚™ 2023-06-27 EFS ãƒãƒ¼ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆæ¯æ¸‡å¯¾ç­–ãƒ¡ãƒ¢ 2023-05-03 AWS CLI ã‚’ä½¿ã£ãŸ EC2 ã¸ã® EBS ãƒœãƒªãƒ¥ãƒ¼ãƒ ã®æ°¸ç¶šåŒ– 2023-05-01 Terraform ã®ãƒ©ãƒƒãƒ‘ãƒ¼ãƒ„ãƒ¼ãƒ«ã€Terragrunt ã®å°å…¥æ¤œè¨¼ã‚’è¡Œã£ã¦ã¿ãŸ 2023-04-27 Lambda ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºç’°å¢ƒæ§‹ç¯‰ãƒ¡ãƒ¢ (SAM | LocalStack | TypeScript) 2023-04-24 OIDC (Git to AWS)ã®ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ¢ 2023-04-26 Packer ã¨ Ansible ã‚’ä½¿ã£ã¦ Amazon Linux 2 ã« NAT ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆã™ã‚‹ 2023-04-11 ãƒ–ãƒ©ã‚¦ã‚¶ã®ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ãƒ­ã‚°ã‚’ Selenium(ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ–ãƒ©ã‚¦ã‚¶)ã§å–å¾—ã™ã‚‹ 2020-08-26 ","permalink":"https://h-neco.github.io/blog/list/","tags":[],"title":"List"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml\n[outputs] home = [\u0026#34;HTML\u0026#34;, \u0026#34;JSON\u0026#34;] Searching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category\n... \u0026#34;contents\u0026#34;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026#34;tags\u0026#34;:{{ .Params.tags | jsonify }}{{end}}, \u0026#34;categories\u0026#34; : {{ .Params.categories | jsonify }}, ... Edit fuse.js options to Search static/js/search.js\nkeys: [ \u0026#34;title\u0026#34;, \u0026#34;contents\u0026#34;, \u0026#34;tags\u0026#34;, \u0026#34;categories\u0026#34; ] ","permalink":"https://h-neco.github.io/search/","tags":null,"title":"Search Results"}]